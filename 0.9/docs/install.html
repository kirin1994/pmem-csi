

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Installation and Usage &mdash; PMEM-CSI v0.9 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/override.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Develop and Contribute" href="DEVELOPMENT.html" />
    <link rel="prev" title="Design and architecture" href="design.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> PMEM-CSI
          

          
          </a>

          
            
            
              <div class="version">
                v0.9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction to PMEM-CSI for Kubernetes*</a></li>
<li class="toctree-l1"><a class="reference internal" href="design.html">Design and architecture</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Installation and Usage</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="#prerequisites">Prerequisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#software-required">Software required</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hardware-required">Hardware required</a></li>
<li class="toctree-l3"><a class="reference internal" href="#persistent-memory-pre-provisioning">Persistent memory pre-provisioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#installation-and-setup">Installation and setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#install-pmem-csi-driver">Install PMEM-CSI driver</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#install-using-the-operator">Install using the operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-via-yaml-files">Install via YAML files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#volume-parameters">Volume parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-volumes">Creating volumes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#troubleshooting">Troubleshooting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#driver-or-operator-fails">Driver or operator fails</a></li>
<li class="toctree-l4"><a class="reference internal" href="#no-driver-pod-created-for-a-node">No driver Pod created for a node</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-pod-getting-assigned-to-a-node-with-no-pmem">Example Pod getting assigned to a node with no PMEM</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example-pod-getting-assigned-to-a-node-with-insufficient-pmem">Example Pod getting assigned to a node with insufficient PMEM</a></li>
<li class="toctree-l4"><a class="reference internal" href="#less-pmem-available-than-expected">Less PMEM available than expected</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#kata-containers-support">Kata Containers support</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ephemeral-inline-volumes">Ephemeral inline volumes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#kubernetes-csi-specific">Kubernetes CSI specific</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generic">Generic</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#raw-block-volumes">Raw block volumes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#enable-scheduler-extensions">Enable scheduler extensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#storage-capacity-tracking">Storage capacity tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metrics-support">Metrics support</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#metrics-data">Metrics data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#prometheus-example">Prometheus example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pmem-csi-deployment-crd">PMEM-CSI Deployment CRD</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pmemcsideployment">PmemCSIDeployment</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#deploymentspec">DeploymentSpec</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deploymentstatus">DeploymentStatus</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deployment-conditions">Deployment Conditions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#driver-component-status">Driver component status</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deployment-events">Deployment Events</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#filing-issues-and-contributing">Filing issues and contributing</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="DEVELOPMENT.html">Develop and Contribute</a></li>
<li class="toctree-l1"><a class="reference internal" href="autotest.html">Automated testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/readme.html">Application examples</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/pmem-csi">Project GitHub repository</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PMEM-CSI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Installation and Usage</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="installation-and-usage">
<h1>Installation and Usage<a class="headerlink" href="#installation-and-usage" title="Permalink to this headline">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>This section summarizes the steps that may be needed during the entire
lifecycle of PMEM in a cluster, starting with the initial preparations and
ending with decommissioning the hardware. The other sections explain
each step in more detail.</p>
<p>When setting up a cluster, the administrator must install the PMEM
hardware on nodes and configure some or all of those instances of PMEM for usage by
PMEM-CSI (<a class="reference external" href="#prerequisites">prerequisites</a>). Nodes where PMEM-CSI is
supposed to run must have a certain <a class="reference external" href="#installation-and-setup">label in
Kubernetes</a>.</p>
<p>The administrator must install PMEM-CSI, using <a class="reference external" href="#install-using-the-operator">the PMEM-CSI
operator</a> (recommended) or with <a class="reference external" href="#install-via-yaml-files">scripts
and YAML files in the source code</a>. The default
install settings should work for most clusters. Some clusters don’t
use <code class="docutils literal notranslate"><span class="pre">/var/lib/kubelet</span></code> as the data directory for kubelet and then the
corresponding PMEM-CSI setting must be changed accordingly because
otherwise kubelet does not find PMEM-CSI. The operator has an option
for that in its API (<code class="docutils literal notranslate"><span class="pre">kubeletDir</span></code> in the <a class="reference external" href="#deploymentspec"><code class="docutils literal notranslate"><span class="pre">DeploymentSpec</span></code></a>),
the YAML files can be edited or modified with
kustomize.</p>
<p>A PMEM-CSI installation can only use <a class="reference external" href="design.html#direct-device-mode">direct device
mode</a> or <a class="reference external" href="design.html#lvm-device-mode">LVM
device mode</a>. It is possible to install
PMEM-CSI twice on the same cluster with different modes, with these restrictions:</p>
<ul class="simple">
<li><p>The driver names must be different.</p></li>
<li><p>The installations must run on different nodes by using different node
labels, or the “usage” parameter of the LVM mode driver installation
one a node must be so that it leaves spaces available for the direct mode
driver installation on that same node.</p></li>
</ul>
<p>The administrator must decide which storage classes shall be available
to users of the cluster. A storage class references a driver
installation by name, which indirectly determines the device mode. A
storage class also chooses which filesystem is used (xfs or ext4) and
enables <a class="reference external" href="#kata-containers-support">Kata Containers support</a>.</p>
<p>Optionally, the administrator can enable <a class="reference external" href="#enable-scheduler-extensions">the scheduler
extensions</a> (recommended) and monitoring
of resource usage via the <a class="reference external" href="#metrics-support">metrics support</a>.</p>
<p>It is <a class="reference external" href="./design.html#dynamic-provisioning-of-local-volumes">recommended</a>
to enable the scheduler extensions in combination with
<code class="docutils literal notranslate"><span class="pre">volumeBindingMode:</span> <span class="pre">WaitForFirstConsumer</span></code> as in the
<a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common/pmem-storageclass-late-binding.yaml"><code class="docutils literal notranslate"><span class="pre">pmem-storageclass-late-binding.yaml</span></code></a>
example. This ensures that pods get scheduled onto nodes that have
sufficient RAM, CPU and PMEM. Without the scheduler extensions, it is
random whether the scheduler picks a node that has PMEM available and
immediate binding (the default volume binding mode) might work
better. However, then pods might not be able to run when the node
where volumes were created are overloaded.</p>
<p>Optionally, the log output format can be changed from the default
“text” format (= the traditional glog format) to “json” (= output via
<a class="reference external" href="https://github.com/uber-go/zap/blob/master/README.md">zap</a>) for easier
processing.</p>
<p>When using the operator, existing PMEM-CSI installations can be
upgraded seamlessly by installing a newer version of the
operator. Downgrading by installing an older version is also
supported, but may need manual work which will be documented in the
release notes.</p>
<p>When using YAML files, the only reliable way of up- or downgrading is
to remove the installation and install anew.</p>
<p>Users can then create PMEM volumes via <a class="reference external" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">persistent volume
claims</a> that
reference the storage classes or via <a class="reference external" href="#ephemeral-inline-volumes">ephemeral inline
volumes</a>.</p>
<p>A node should only be removed from a cluster after ensuring that there
is no pod running on it which uses PMEM and that there is no
persistent volume (<code class="docutils literal notranslate"><span class="pre">PV</span></code>) on it. This can be checked via <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">-o</span> <span class="pre">yaml</span> <span class="pre">pv</span></code> and looking for a <code class="docutils literal notranslate"><span class="pre">nodeAffinity</span></code> entry that references the
node or via metrics data for the node. When removing a node or even
the entire PMEM-CSI driver installation too soon, attempts to remove
pods or volumes via the Kubernetes API will fail. Administrators can
recover from that by force-deleting PVs for which the underlying
hardware has already been removed.</p>
<p>By default, PMEM-CSI wipes volumes after usage
(<a class="reference external" href="#kubernetes-csi-specific"><code class="docutils literal notranslate"><span class="pre">eraseAfter</span></code></a>), so shredding PMEM hardware
after decomissioning it is optional.</p>
</section>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h2>
<section id="software-required">
<h3>Software required<a class="headerlink" href="#software-required" title="Permalink to this headline">¶</a></h3>
<p>The recommended mimimum Linux kernel version for running the PMEM-CSI driver is 4.15. See <a class="reference external" href="https://pmem.io/2018/05/15/using_persistent_memory_devices_with_the_linux_device_mapper.html">Persistent Memory Programming</a> for more details about supported kernel versions.</p>
</section>
<section id="hardware-required">
<h3>Hardware required<a class="headerlink" href="#hardware-required" title="Permalink to this headline">¶</a></h3>
<p>Persistent memory device(s) are required for operation. However, some
development and testing can be done using QEMU-emulated persistent
memory devices. See the <a class="reference external" href="autotest.html#qemu-and-kubernetes">“QEMU and Kubernetes”</a>
section for the commands that create such a virtual test cluster.</p>
</section>
<section id="persistent-memory-pre-provisioning">
<h3>Persistent memory pre-provisioning<a class="headerlink" href="#persistent-memory-pre-provisioning" title="Permalink to this headline">¶</a></h3>
<p>The PMEM-CSI driver needs pre-provisioned regions on the NVDIMM
device(s). The PMEM-CSI driver itself intentionally leaves that to the
administrator who then can decide how much and how PMEM is to be used
for PMEM-CSI.</p>
<p>Beware that the PMEM-CSI driver will run without errors on a node
where PMEM was not prepared for it. It will then report zero local
storage for that node, something that currently is only visible in the
log files.</p>
<p>When running the Kubernetes cluster and PMEM-CSI on bare metal,
the <a class="reference external" href="https://github.com/intel/ipmctl">ipmctl</a> utility can be used to create regions.
App Direct Mode has two configuration options - interleaved or non-interleaved.
One region per each NVDIMM is created in non-interleaved configuration.
In such a configuration, a PMEM-CSI volume cannot be larger than one NVDIMM.</p>
<p>Example of creating regions without interleaving, using all NVDIMMs:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ipmctl create -goal <span class="nv">PersistentMemoryType</span><span class="o">=</span>AppDirectNotInterleaved
</pre></div>
</div>
<p>Alternatively, multiple NVDIMMs can be combined to form an interleaved set.
This causes the data to be striped over multiple NVDIMM devices
for improved read/write performance and allowing one region (also, PMEM-CSI volume)
to be larger than single NVDIMM.</p>
<p>Example of creating regions in interleaved mode, using all NVDIMMs:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ipmctl create -goal <span class="nv">PersistentMemoryType</span><span class="o">=</span>AppDirect
</pre></div>
</div>
<p>When running inside virtual machines, each virtual machine typically
already gets access to one region and <code class="docutils literal notranslate"><span class="pre">ipmctl</span></code> is not needed inside
the virtual machine. Instead, that region must be made available for
use with PMEM-CSI because when the virtual machine comes up for the
first time, the entire region is already allocated for use as a single
block device:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ndctl list -RN
<span class="go">{</span>
<span class="go">  &quot;regions&quot;:[</span>
<span class="go">    {</span>
<span class="go">      &quot;dev&quot;:&quot;region0&quot;,</span>
<span class="go">      &quot;size&quot;:34357641216,</span>
<span class="go">      &quot;available_size&quot;:0,</span>
<span class="go">      &quot;max_available_extent&quot;:0,</span>
<span class="go">      &quot;type&quot;:&quot;pmem&quot;,</span>
<span class="go">      &quot;persistence_domain&quot;:&quot;unknown&quot;,</span>
<span class="go">      &quot;namespaces&quot;:[</span>
<span class="go">        {</span>
<span class="go">          &quot;dev&quot;:&quot;namespace0.0&quot;,</span>
<span class="go">          &quot;mode&quot;:&quot;raw&quot;,</span>
<span class="go">          &quot;size&quot;:34357641216,</span>
<span class="go">          &quot;sector_size&quot;:512,</span>
<span class="go">          &quot;blockdev&quot;:&quot;pmem0&quot;</span>
<span class="go">        }</span>
<span class="go">      ]</span>
<span class="go">    }</span>
<span class="go">  ]</span>
<span class="go">}</span>
<span class="gp">$ </span>ls -l /dev/pmem*
<span class="go">brw-rw---- 1 root disk 259, 0 Jun  4 16:41 /dev/pmem0</span>
</pre></div>
</div>
<p>Labels must be initialized in such a region, which must be performed
once after the first boot:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>ndctl disable-region region0
<span class="go">disabled 1 region</span>
<span class="gp">$ </span>ndctl init-labels nmem0
<span class="go">initialized 1 nmem</span>
<span class="gp">$ </span>ndctl enable-region region0
<span class="go">enabled 1 region</span>
<span class="gp">$ </span>ndctl list -RN
<span class="go">[</span>
<span class="go">  {</span>
<span class="go">    &quot;dev&quot;:&quot;region0&quot;,</span>
<span class="go">    &quot;size&quot;:34357641216,</span>
<span class="go">    &quot;available_size&quot;:34357641216,</span>
<span class="go">    &quot;max_available_extent&quot;:34357641216,</span>
<span class="go">    &quot;type&quot;:&quot;pmem&quot;,</span>
<span class="go">    &quot;iset_id&quot;:10248187106440278,</span>
<span class="go">    &quot;persistence_domain&quot;:&quot;unknown&quot;</span>
<span class="go">  }</span>
<span class="go">]</span>
<span class="gp">$ </span>ls -l /dev/pmem*
<span class="go">ls: cannot access &#39;/dev/pmem*&#39;: No such file or directory</span>
</pre></div>
</div>
</section>
</section>
<section id="installation-and-setup">
<h2>Installation and setup<a class="headerlink" href="#installation-and-setup" title="Permalink to this headline">¶</a></h2>
<p>This section assumes that a Kubernetes cluster is already available
with at least one node that has persistent memory device(s). For development or
testing, it is also possible to use a cluster that runs on QEMU virtual
machines, see the <a class="reference external" href="autotest.html#qemu-and-kubernetes">“QEMU and Kubernetes”</a>.</p>
<ul class="simple">
<li><p><strong>Make sure that the alpha feature gates CSINodeInfo and CSIDriverRegistry are enabled</strong></p></li>
</ul>
<p>The method to configure alpha feature gates may vary, depending on the Kubernetes deployment.
It may not be necessary anymore when the feature has reached beta state, which depends
on the Kubernetes version.</p>
<ul class="simple">
<li><p><strong>Label the cluster nodes that provide persistent memory device(s)</strong></p></li>
</ul>
<p>PMEM-CSI manages PMEM on those nodes that have a certain label. For
historic reasons, the default in the YAML files and the operator
settings is to use a label <code class="docutils literal notranslate"><span class="pre">storage</span></code> with the value <code class="docutils literal notranslate"><span class="pre">pmem</span></code>.</p>
<p>Such a label can be set for each node manually with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl label node &lt;your node&gt; <span class="nv">storage</span><span class="o">=</span>pmem
</pre></div>
</div>
<p>Alternatively, the <a class="reference external" href="https://kubernetes-sigs.github.io/node-feature-discovery/stable/get-started/index.html">Node Feature
Discovery (NFD)</a>
add-on can be used to label nodes automatically. In that case, the
default PMEM-CSI node selector has to be changed to
<code class="docutils literal notranslate"><span class="pre">&quot;feature.node.kubernetes.io/memory-nv.dax&quot;:</span> <span class="pre">&quot;true&quot;</span></code>. The operator has
the <a class="reference external" href="https://kubernetes-sigs.github.io/node-feature-discovery/stable/get-started/index.html"><code class="docutils literal notranslate"><span class="pre">nodeSelector</span></code>
field</a>
for that. For the YAML files a kustomize patch can be used.</p>
<section id="install-pmem-csi-driver">
<h3>Install PMEM-CSI driver<a class="headerlink" href="#install-pmem-csi-driver" title="Permalink to this headline">¶</a></h3>
<p>PMEM-CSI driver can be deployed to a Kubernetes cluster either using the
PMEM-CSI operator or by using reference yaml files provided in source code.</p>
<section id="install-using-the-operator">
<h4>Install using the operator<a class="headerlink" href="#install-using-the-operator" title="Permalink to this headline">¶</a></h4>
<p>The <a class="reference external" href="./design.html#pmem-csi-operator">PMEM-CSI operator</a> facilitates deploying and managing
the PMEM-CSI driver on a Kubernetes cluster.</p>
<section id="installing-the-operator-from-operator-hub">
<h5>Installing the operator from Operator Hub<a class="headerlink" href="#installing-the-operator-from-operator-hub" title="Permalink to this headline">¶</a></h5>
<p>If your cluster supports managing the operators using the <a class="reference external" href="https://olm.operatorframework.io/">Operator
Lifecycle Manager</a>, then it is
recommended to install the PMEM-CSI operator from the
<a class="reference external" href="https://operatorhub.io/operator/pmem-csi-operator">OperatorHub</a>. Follow
the instructions shown by the “Install” button. When using this
approach, the operator itself always runs with default parameters, in
particular log output in “text” format.</p>
</section>
<section id="installing-the-operator-from-yaml">
<h5>Installing the operator from YAML<a class="headerlink" href="#installing-the-operator-from-yaml" title="Permalink to this headline">¶</a></h5>
<p>Alternatively, the you can install the operator manually from YAML files.
First install the PmemCSIDeployment CRD:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl create -f https://github.com/intel/pmem-csi/raw/v0.9.1/deploy/crd/pmem-csi.intel.com_pmemcsideployments.yaml
</pre></div>
</div>
<p>Then install the PMEM-CSI operator itself:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl create -f https://github.com/intel/pmem-csi/raw/v0.9.1/deploy/operator/pmem-csi-operator.yaml
</pre></div>
</div>
<p>The operator gets deployed in a namespace called ‘pmem-csi’ which gets created by that YAML file.</p>
<p><strong>WARNING:</strong> This YAML file cannot be used to stop just the operator while
keeping the PMEM-CSI deployments running. That’s because something like
<code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">delete</span> <span class="pre">-f</span> <span class="pre">pmem-csi-operator.yaml</span></code> will delete the <code class="docutils literal notranslate"><span class="pre">pmem-csi</span></code>
namespace which then also causes all PMEM-CSI deployments that might have
been created in that namespace to be deleted.</p>
</section>
<section id="create-a-driver-deployment">
<h5>Create a driver deployment<a class="headerlink" href="#create-a-driver-deployment" title="Permalink to this headline">¶</a></h5>
<p>Once the operator is installed and running, it is ready to handle
<code class="docutils literal notranslate"><span class="pre">PmemCSIDeployment</span></code> objects in the <code class="docutils literal notranslate"><span class="pre">pmem-csi.intel.com</span></code> API group.
Refer to the <a class="reference external" href="#pmem-csi-deployment-crd">PmemCSIDeployment CRD API</a>
for a complete list of supported properties.</p>
<p>Here is a minimal example driver deployment created with a custom resource:</p>
<p><strong>NOTE</strong>: <code class="docutils literal notranslate"><span class="pre">nodeSelector</span></code> must match the node label that was set in the
<a class="reference external" href="#installation-and-setup">installation and setup</a> section.</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl create -f - &lt;&lt;EOF
<span class="go">apiVersion: pmem-csi.intel.com/v1beta1</span>
<span class="go">kind: PmemCSIDeployment</span>
<span class="go">metadata:</span>
<span class="go">  name: pmem-csi.intel.com</span>
<span class="go">spec:</span>
<span class="go">  deviceMode: lvm</span>
<span class="go">  nodeSelector:</span>
<span class="go">    feature.node.kubernetes.io/memory-nv.dax: &quot;true&quot;</span>
<span class="go">EOF</span>
</pre></div>
</div>
<p>This uses the same <code class="docutils literal notranslate"><span class="pre">pmem-csi.intel.com</span></code> driver name as the YAML files
in <a class="reference external" href="https://github.com/intel/pmem-csi/tree/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy"><code class="docutils literal notranslate"><span class="pre">deploy</span></code></a> and the node label created by NFD (see the <a class="reference external" href="#installation-and-setup">hardware
installation and setup section</a>).</p>
<p>Once the above deployment installation is successful, we can see all the driver
pods in <code class="docutils literal notranslate"><span class="pre">Running</span></code> state:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pmemcsideployments
<span class="go">NAME                 DEVICEMODE   NODESELECTOR   IMAGE   STATUS   AGE</span>
<span class="go">pmem-deployment      lvm                                 Running  50s</span>

<span class="gp">$ </span>kubectl describe pmemcsideployment/pmem-csi.intel.com
<span class="go">Name:         pmem-csi.intel.com</span>
<span class="go">Namespace:</span>
<span class="go">Labels:       &lt;none&gt;</span>
<span class="go">Annotations:  &lt;none&gt;</span>
<span class="go">API Version:  pmem-csi.intel.com/v1beta1</span>
<span class="go">Kind:         PmemCSIDeployment</span>
<span class="go">Metadata:</span>
<span class="go">  Creation Timestamp:  2020-10-07T07:31:58Z</span>
<span class="go">  Generation:          1</span>
<span class="go">  Managed Fields:</span>
<span class="go">    ...</span>
<span class="go">  Resource Version:  1235740</span>
<span class="go">  Self Link:         /apis/pmem-csi.intel.com/v1beta1/pmemcsideployments/pmem-csi.intel.com</span>
<span class="go">  UID:               d8635490-53fa-4eec-970d-cd4c76f53b23</span>
<span class="go">Spec:</span>
<span class="go">  Device Mode:  lvm</span>
<span class="go">  Node Selector:</span>
<span class="go">    Storage:  pmem</span>
<span class="go">Status:</span>
<span class="go">  Conditions:</span>
<span class="go">    Last Update Time:  2020-10-07T07:32:00Z</span>
<span class="go">    Reason:            Driver certificates are available.</span>
<span class="go">    Status:            True</span>
<span class="go">    Type:              CertsReady</span>
<span class="go">    Last Update Time:  2020-10-07T07:32:02Z</span>
<span class="go">    Reason:            Driver deployed successfully.</span>
<span class="go">    Status:            True</span>
<span class="go">    Type:              DriverDeployed</span>
<span class="go">  Driver Components:</span>
<span class="go">    Component:     Controller</span>
<span class="go">    Last Updated:  2020-10-08T07:45:13Z</span>
<span class="go">    Reason:        1 instance(s) of controller driver is running successfully</span>
<span class="go">    Status:        Ready</span>
<span class="go">    Component:     Node</span>
<span class="go">    Last Updated:  2020-10-08T07:45:11Z</span>
<span class="go">    Reason:        All 3 node driver pod(s) running successfully</span>
<span class="go">    Status:        Ready</span>
<span class="go">  Last Updated:    2020-10-07T07:32:21Z</span>
<span class="go">  Phase:           Running</span>
<span class="go">  Reason:          All driver components are deployed successfully</span>
<span class="go">Events:</span>
<span class="go">  Type    Reason         Age   From               Message</span>
<span class="go">  ----    ------         ----  ----               -------</span>
<span class="go">  Normal  NewDeployment  58s   pmem-csi-operator  Processing new driver deployment</span>
<span class="go">  Normal  Running        39s   pmem-csi-operator  Driver deployment successful</span>

<span class="gp">$ </span>kubectl get pod -n pmem-csi
<span class="go">NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="go">pmem-csi-intel-com-controller-0    2/2     Running   0          51s</span>
<span class="go">pmem-csi-intel-com-node-4x7cv      2/2     Running   0          50s</span>
<span class="go">pmem-csi-intel-com-node-6grt6      2/2     Running   0          50s</span>
<span class="go">pmem-csi-intel-com-node-msgds      2/2     Running   0          51s</span>
<span class="go">pmem-csi-operator-749c7c7c69-k5k8n 1/1     Running   0          3m</span>
</pre></div>
</div>
</section>
</section>
<section id="install-via-yaml-files">
<h4>Install via YAML files<a class="headerlink" href="#install-via-yaml-files" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p><strong>Get source code</strong></p></li>
</ul>
<p>PMEM-CSI uses Go modules and thus can be checked out and (if that should be desired)
built anywhere in the filesystem. Pre-built container images are available and thus
users don’t need to build from source, but they may need some additional files
for the following sections.
To get the source code, use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git clone https://github.com/intel/pmem-csi
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Choose a namespace</strong></p></li>
</ul>
<p>By default, setting up certificates as described in the next step will
automatically create a <code class="docutils literal notranslate"><span class="pre">pmem-csi</span></code> namespace if it does not exist yet.
Later the driver will be installed in that namespace.</p>
<p>This can be changed by:</p>
<ul class="simple">
<li><p>setting the <code class="docutils literal notranslate"><span class="pre">TEST_DRIVER_NAMESPACE</span></code> env variable to a different name
when invoking <code class="docutils literal notranslate"><span class="pre">setup-ca-kubernetes.sh</span></code> and</p></li>
<li><p>modifying the deployment with kustomize as explained below.</p></li>
<li><p><strong>Set up certificates</strong></p></li>
</ul>
<p>Certificates are required as explained in <a class="reference external" href="design.html#security">Security</a> for
running the PMEM-CSI <a class="reference external" href="design.html#scheduler-extender">scheduler extender</a> and
<a class="reference external" href="design.html#pod-admission-webhook">webhook</a>. If those are not used, then certificate
creation can be skipped. However, the YAML deployment files always create the PMEM-CSI
controller StatefulSet which needs the certificates. Without them, the
<code class="docutils literal notranslate"><span class="pre">pmem-csi-intel-com-controller-0</span></code> pod cannot start, so it is recommended to create
certificates or customize the deployment so that this StatefulSet is not created.</p>
<p>Certificates can be created by running the <code class="docutils literal notranslate"><span class="pre">./test/setup-ca-kubernetes.sh</span></code> script for your cluster.
This script requires “cfssl” tools which can be downloaded.
These are the steps for manual set-up of certificates:</p>
<ul class="simple">
<li><p>Download cfssl tools</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl -L https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -o _work/bin/cfssl --create-dirs
<span class="gp">$ </span>curl -L https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -o _work/bin/cfssljson --create-dirs
<span class="gp">$ </span>chmod a+x _work/bin/cfssl _work/bin/cfssljson
</pre></div>
</div>
<ul class="simple">
<li><p>Run certificates set-up script</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">KUBCONFIG</span><span class="o">=</span><span class="s2">&quot;&lt;&lt;your cluster kubeconfig path&gt;&gt;&quot;</span> <span class="nv">PATH</span><span class="o">=</span><span class="s2">&quot;</span><span class="nv">$PWD</span><span class="s2">/_work/bin:</span><span class="nv">$PATH</span><span class="s2">&quot;</span> ./test/setup-ca-kubernetes.sh
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Deploy the driver to Kubernetes</strong></p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">deploy/kubernetes-&lt;kubernetes</span> <span class="pre">version&gt;</span></code> directory contains
<code class="docutils literal notranslate"><span class="pre">pmem-csi*.yaml</span></code> files which can be used to deploy the driver on that
Kubernetes version. The files in the directory with the highest
Kubernetes version might also work for more recent Kubernetes
releases. All of these deployments use images published by Intel on
<a class="reference external" href="https://hub.docker.com/u/intel">Docker Hub</a>.</p>
<p>For each Kubernetes version, four different deployment variants are provided:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">direct</span></code> or <code class="docutils literal notranslate"><span class="pre">lvm</span></code>: one uses direct device mode, the other LVM device mode.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">testing</span></code>: the variants with <code class="docutils literal notranslate"><span class="pre">testing</span></code> in the name enable debugging
features and shouldn’t be used in production.</p></li>
</ul>
<p>For example, to deploy for production with LVM device mode onto Kubernetes 1.17, use:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl create -f deploy/kubernetes-1.17/pmem-csi-lvm.yaml
</pre></div>
</div>
<p>The PMEM-CSI <a class="reference external" href="design.html#scheduler-extender">scheduler extender</a> and
<a class="reference external" href="design.html#pod-admission-webhook">webhook</a> are not enabled in this basic
installation. See <a class="reference external" href="#enable-scheduler-extensions">below</a> for
instructions about that.</p>
<p>These variants were generated with
<a class="reference external" href="https://github.com/kubernetes-sigs/kustomize"><code class="docutils literal notranslate"><span class="pre">kustomize</span></code></a>.
<code class="docutils literal notranslate"><span class="pre">kubectl</span></code> &gt;= 1.14 includes some support for that. The sub-directories
of <a class="reference external" href="https://github.com/intel/pmem-csi/tree/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/kustomize">deploy/kustomize</a><code class="docutils literal notranslate"><span class="pre">-&lt;kubernetes</span> <span class="pre">version&gt;</span></code> can be used as bases
for <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">kustomize</span></code>. For example:</p>
<ul>
<li><p>Change namespace:</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir -p my-pmem-csi-deployment
<span class="gp">$ </span>cat &gt;my-pmem-csi-deployment/kustomization.yaml &lt;&lt;EOF
<span class="go">namespace: pmem-driver</span>
<span class="go">bases:</span>
<span class="go">  - ../deploy/kubernetes-1.17/lvm</span>
<span class="go">EOF</span>
<span class="gp">$ </span>kubectl create --kustomize my-pmem-csi-deployment
</pre></div>
</div>
</li>
<li><p>Configure how much PMEM is used by PMEM-CSI for LVM
(see <a class="reference external" href="design.html#namespace-modes-in-lvm-device-mode">Namespace modes in LVM device mode</a>):</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir -p my-pmem-csi-deployment
<span class="gp">$ </span>cat &gt;my-pmem-csi-deployment/kustomization.yaml &lt;&lt;EOF
<span class="go">bases:</span>
<span class="go">  - ../deploy/kubernetes-1.17/lvm</span>
<span class="go">patchesJson6902:</span>
<span class="go">  - target:</span>
<span class="go">      group: apps</span>
<span class="go">      version: v1</span>
<span class="go">      kind: DaemonSet</span>
<span class="go">      name: pmem-csi-node</span>
<span class="go">      namespace: pmem-csi</span>
<span class="go">    path: lvm-parameters-patch.yaml</span>
<span class="go">EOF</span>
<span class="gp">$ </span>cat &gt;my-pmem-csi-deployment/lvm-parameters-patch.yaml &lt;&lt;EOF
<span class="gp"># </span>pmem-driver is <span class="k">in</span> the container <span class="c1">#0. Append arguments at the end.</span>
<span class="go">- op: add</span>
<span class="go">  path: /spec/template/spec/containers/0/args/-</span>
<span class="go">  value: &quot;-pmemPercentage=90&quot;</span>
<span class="go">EOF</span>
<span class="gp">$ </span>kubectl create --kustomize my-pmem-csi-deployment
</pre></div>
</div>
</li>
<li><p>Wait until all pods reach ‘Running’ status</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pods -n pmem-csi
<span class="go">NAME                    READY   STATUS    RESTARTS   AGE</span>
<span class="go">pmem-csi-intel-com-node-8kmxf     2/2     Running   0          3m15s</span>
<span class="go">pmem-csi-intel-com-node-bvx7m     2/2     Running   0          3m15s</span>
<span class="go">pmem-csi-intel-com-controller-0   2/2     Running   0          3m15s</span>
<span class="go">pmem-csi-intel-com-node-fbmpg     2/2     Running   0          3m15s</span>
</pre></div>
</div>
</section>
</section>
<section id="volume-parameters">
<h3>Volume parameters<a class="headerlink" href="#volume-parameters" title="Permalink to this headline">¶</a></h3>
<p>A Kubernetes cluster administrators must define some volume parameters
like the filesystem type in <a class="reference external" href="https://kubernetes.io/docs/concepts/storage/storage-classes">storage
classes</a>.
Users then reference those storage classes when requesting generic
ephemeral inline or persistent volumes. The size of volumes can be chosen
by users.</p>
<p><code class="docutils literal notranslate"><span class="pre">xfs</span></code> and <code class="docutils literal notranslate"><span class="pre">ext4</span></code> are supported filesystem types. In addition to the
normal parameters defined by Kubernetes, PMEM-CSI supports the
following custom parameters in a storage class:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>key</th>
<th>meaning</th>
<th>optional</th>
<th>values</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>eraseAfter</code></td>
<td>Clear all data by overwriting with zeroes after use and before<br> deleting the volume</td>
<td>Yes</td>
<td><code>true</code> (default),<br> <code>false</code></td>
</tr>
<tr>
<td><code>kataContainers</code></td>
<td>Prepare volume for use with DAX in Kata Containers.</td>
<td>Yes</td>
<td><code>false/0/f/FALSE</code> (default),<br> <code>true/1/t/TRUE</code></td>
</tr>
</tbody>
</table></section>
<section id="creating-volumes">
<h3>Creating volumes<a class="headerlink" href="#creating-volumes" title="Permalink to this headline">¶</a></h3>
<p>This section uses files from the <a class="reference external" href="https://github.com/intel/pmem-csi/tree/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common">common example directory</a>.
It is not necessary to check out the repository to use them.</p>
<p>Create a storage class with late binding, the recommended mode:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f https://github.com/intel/pmem-csi/raw/v0.9.1/deploy/common/pmem-storageclass-late-binding.yaml
<span class="go">storageclass.storage.k8s.io/pmem-csi-sc-late-binding created</span>
</pre></div>
</div>
<p>Then request a volume which uses that class:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f https://github.com/intel/pmem-csi/raw/v0.9.1/deploy/common/pmem-pvc-late-binding.yaml
<span class="go">persistentvolumeclaim/pmem-csi-pvc-late-binding created</span>
</pre></div>
</div>
<p>At this point, the volume is not yet getting created because of the
late binding mode:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl describe pvc/pmem-csi-pvc-late-binding
<span class="go">Name:          pmem-csi-pvc-late-binding</span>
<span class="go">Namespace:     default</span>
<span class="go">StorageClass:  pmem-csi-sc-late-binding</span>
<span class="go">Status:        Pending</span>
<span class="go">Volume:        </span>
<span class="go">Labels:        &lt;none&gt;</span>
<span class="go">Annotations:   &lt;none&gt;</span>
<span class="go">Finalizers:    [kubernetes.io/pvc-protection]</span>
<span class="go">Capacity:      </span>
<span class="go">Access Modes:  </span>
<span class="go">VolumeMode:    Filesystem</span>
<span class="go">Used By:       &lt;none&gt;</span>
<span class="go">Events:</span>
<span class="go">  Type    Reason                Age               From                         Message</span>
<span class="go">  ----    ------                ----              ----                         -------</span>
<span class="go">  Normal  WaitForFirstConsumer  0s (x2 over 14s)  persistentvolume-controller  waiting for first consumer to be created before binding</span>
</pre></div>
</div>
<p>The volume gets created once the first Pod starts to use it, on a node that is suitable for that Pod:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl apply -f https://github.com/intel/pmem-csi/raw/v0.9.1/deploy/common/pmem-app-late-binding.yaml
<span class="go">pod/my-csi-app created</span>
</pre></div>
</div>
<p>After a short while, the volume is created and the pod can run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pvc,pods -o wide
<span class="go">NAME                                              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS               AGE</span>
<span class="go">persistentvolumeclaim/pmem-csi-pvc-late-binding   Bound    pvc-ade8dc48-a4c0-4f30-b479-84460a3e0591   4Gi        RWO            pmem-csi-sc-late-binding   55s</span>

<span class="go">NAME             READY   STATUS    RESTARTS   AGE</span>
<span class="go">pod/my-csi-app   1/1     Running   0          47s</span>
</pre></div>
</div>
<p>The volume was mounted with <code class="docutils literal notranslate"><span class="pre">dax=always</span></code>, therefore all file operations and memory regions mapped from that
volume into the address space of an application directly access the underlying PMEM:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl <span class="nb">exec</span> my-csi-app -- df /data
<span class="go">Filesystem                                                                              1K-blocks  Used Available Use% Mounted on</span>
<span class="go">/dev/ndbus0region0fsdax/pvc-7d-83241976933418f96748a1c18d500c6cba91c1dfaa87145b7893569c   4062912 16376   3820440   1% /data</span>

<span class="gp">$ </span>kubectl <span class="nb">exec</span> my-csi-app -- mount <span class="p">|</span>grep /data
<span class="go">/dev/ndbus0region0fsdax/pvc-7d-83241976933418f96748a1c18d500c6cba91c1dfaa87145b7893569c on /data type ext4 (rw,relatime,seclabel,dax=always)</span>
</pre></div>
</div>
</section>
<section id="troubleshooting">
<h3>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this headline">¶</a></h3>
<p>A few things can go wrong when trying out the previous example.</p>
<section id="driver-or-operator-fails">
<h4>Driver or operator fails<a class="headerlink" href="#driver-or-operator-fails" title="Permalink to this headline">¶</a></h4>
<p>This shows up in <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">pods</span> <span class="pre">--all-namespaces</span></code> as failed Pods
and can be investigated with <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">describe</span> <span class="pre">--namespace</span> <span class="pre">&lt;driver</span> <span class="pre">namespace&gt;</span> <span class="pre">pods/&lt;pod</span> <span class="pre">name&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">logs</span> <span class="pre">--namespace</span> <span class="pre">&lt;driver</span> <span class="pre">namespace&gt;</span> <span class="pre">&lt;pod</span> <span class="pre">name&gt;</span> <span class="pre">pmem-driver</span></code> or one of the other containers
in that Pod.</p>
<p>When using deployment files from the <code class="docutils literal notranslate"><span class="pre">devel</span></code> branch, the corresponding
container <code class="docutils literal notranslate"><span class="pre">canary</span></code> image might not have been published yet. Better use
the <a class="reference external" href="https://intel.github.io/pmem-csi/">latest stable release</a>.</p>
</section>
<section id="no-driver-pod-created-for-a-node">
<h4>No driver Pod created for a node<a class="headerlink" href="#no-driver-pod-created-for-a-node" title="Permalink to this headline">¶</a></h4>
<p>This can be checked with <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">pods</span> <span class="pre">--all-namespaces</span> <span class="pre">-o</span> <span class="pre">wide</span></code>.
Have nodes been labeled as expected by the driver deployment? Check
with <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">nodes</span> <span class="pre">-o</span> <span class="pre">yaml</span></code>.</p>
</section>
<section id="example-pod-getting-assigned-to-a-node-with-no-pmem">
<h4>Example Pod getting assigned to a node with no PMEM<a class="headerlink" href="#example-pod-getting-assigned-to-a-node-with-no-pmem" title="Permalink to this headline">¶</a></h4>
<p>This can happen on clusters where only some worker nodes have PMEM and
the <a class="reference external" href="#enable-scheduler-extensions">PMEM-CSI scheduler extensions</a> are
not enabled. This can be checked by looking at the <code class="docutils literal notranslate"><span class="pre">selected-node</span></code>
annotation of the PVC:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pvc/pmem-csi-pvc-late-binding -o yaml <span class="p">|</span> grep <span class="s1">&#39; volume.kubernetes.io/selected-node:&#39;</span>
<span class="go">    volume.kubernetes.io/selected-node: pmem-csi-pmem-govm-worker2</span>
</pre></div>
</div>
<p>The PMEM-CSI controller pod will detect this and ask the scheduler to
pick a node anew by removing that annotation, but it is random whether
the next choice is better and starting the Pod may get delayed.</p>
<p>To avoid this, enable the scheduler extensions.</p>
</section>
<section id="example-pod-getting-assigned-to-a-node-with-insufficient-pmem">
<h4>Example Pod getting assigned to a node with insufficient PMEM<a class="headerlink" href="#example-pod-getting-assigned-to-a-node-with-insufficient-pmem" title="Permalink to this headline">¶</a></h4>
<p>This also can only happen when the <a class="reference external" href="#enable-scheduler-extensions">PMEM-CSI scheduler
extensions</a> are not enabled. Then volume
creation is attempted repeatedly, potentially on different nodes, but
fails with <code class="docutils literal notranslate"><span class="pre">not</span> <span class="pre">enough</span> <span class="pre">space</span></code> errors:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl describe pvc/pmem-csi-pvc-late-binding
<span class="go">Name:          pmem-csi-pvc-late-binding</span>
<span class="go">Namespace:     default</span>
<span class="go">StorageClass:  pmem-csi-sc-late-binding</span>
<span class="go">Status:        Pending</span>
<span class="go">Volume:        </span>
<span class="go">Labels:        &lt;none&gt;</span>
<span class="go">Annotations:   volume.beta.kubernetes.io/storage-provisioner: pmem-csi.intel.com</span>
<span class="go">Finalizers:    [kubernetes.io/pvc-protection]</span>
<span class="go">Capacity:      </span>
<span class="go">Access Modes:  </span>
<span class="go">VolumeMode:    Filesystem</span>
<span class="go">Used By:       my-csi-app</span>
<span class="go">Events:</span>
<span class="go">  Type     Reason                Age                     From                                                                                   Message</span>
<span class="go">  ----     ------                ----                    ----                                                                                   -------</span>
<span class="go">  Normal   WaitForFirstConsumer  7m30s                   persistentvolume-controller                                                            waiting for first consumer to be created before binding</span>
<span class="go">  Normal   WaitForPodScheduled   6m (x15 over 7m19s)     persistentvolume-controller                                                            waiting for pod my-csi-app to be scheduled</span>
<span class="go">  Warning  ProvisioningFailed    3m59s (x12 over 7m19s)  pmem-csi.intel.com_pmem-csi-intel-com-node-nwkqv_cc2984e6-915f-4cf2-93a0-e143da407917  failed to provision volume with StorageClass &quot;pmem-csi-sc-late-binding&quot;: rpc error: code = ResourceExhausted desc = Node CreateVolume: device creation failed: not enough space</span>
<span class="go">  Warning  ProvisioningFailed    2m47s (x12 over 7m18s)  pmem-csi.intel.com_pmem-csi-intel-com-node-9vlhf_6ac47898-58bf-45e1-b601-5d8f39d21f4e  failed to provision volume with StorageClass &quot;pmem-csi-sc-late-binding&quot;: rpc error: code = ResourceExhausted desc = Node CreateVolume: device creation failed: not enough space</span>
<span class="go">  Normal   ExternalProvisioning  2m23s (x28 over 7m19s)  persistentvolume-controller                                                            waiting for a volume to be created, either by external provisioner &quot;pmem-csi.intel.com&quot; or manually created by system administrator</span>
<span class="go">  Normal   Provisioning          2m11s (x14 over 7m18s)  pmem-csi.intel.com_pmem-csi-intel-com-node-9vlhf_6ac47898-58bf-45e1-b601-5d8f39d21f4e  External provisioner is provisioning volume for claim &quot;default/pmem-csi-pvc-late-binding&quot;</span>
<span class="go">  Normal   Provisioning          107s (x16 over 7m19s)   pmem-csi.intel.com_pmem-csi-intel-com-node-nwkqv_cc2984e6-915f-4cf2-93a0-e143da407917  External provisioner is provisioning volume for claim &quot;default/pmem-csi-pvc-late-binding&quot;</span>
</pre></div>
</div>
<p>The scheduler extensions prevent these useless attempts on nodes with
insufficient PMEM. When none of the available nodes have sufficient
PMEM, the attempt to schedule the example Pod fails:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl describe pod/my-csi-app
<span class="go">Name:         my-csi-app</span>
<span class="go">Namespace:    default</span>
<span class="go">...</span>
<span class="go">Events:</span>
<span class="go">  Type     Reason            Age                From               Message</span>
<span class="go">  ----     ------            ----               ----               -------</span>
<span class="go">  Warning  FailedScheduling  12s (x2 over 12s)  default-scheduler  0/4 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn&#39;t tolerate, 3 only 63484MiB of PMEM available, need 400GiB.</span>
</pre></div>
</div>
</section>
<section id="less-pmem-available-than-expected">
<h4>Less PMEM available than expected<a class="headerlink" href="#less-pmem-available-than-expected" title="Permalink to this headline">¶</a></h4>
<p>This is usually the result of not preparing the node(s) as describe in
<a class="reference external" href="#persistent-memory-pre-provisioning">persistent memory
pre-provisioning</a>.</p>
<p>One way of checking this is to look at the logs of the PMEM-CSI driver
on a node. In this case, <code class="docutils literal notranslate"><span class="pre">region0</span></code> was completely unused and the
driver was configured to use 50% of that for an LVM volume group:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl get pods --all-namespaces -l app.kubernetes.io/name<span class="o">=</span>pmem-csi-node -o wide
<span class="go">NAMESPACE   NAME                            READY   STATUS    RESTARTS   AGE   IP                NODE                         NOMINATED NODE   READINESS GATES</span>
<span class="go">pmem-csi    pmem-csi-intel-com-node-d2mfh   3/3     Running   0          75s   192.168.200.66    pmem-csi-pmem-govm-worker3   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pmem-csi    pmem-csi-intel-com-node-jkbgz   3/3     Running   0          75s   192.168.133.134   pmem-csi-pmem-govm-worker1   &lt;none&gt;           &lt;none&gt;</span>
<span class="go">pmem-csi    pmem-csi-intel-com-node-th56d   3/3     Running   0          75s   192.168.220.67    pmem-csi-pmem-govm-worker2   &lt;none&gt;           &lt;none&gt;</span>

<span class="gp">$ </span>kubectl logs -n pmem-csi pmem-csi-intel-com-node-jkbgz pmem-driver
<span class="go">I0526 14:40:15.350646       1 main.go:69] Version: v0.9.0-88-g602e0f88c</span>
<span class="go">I0526 14:40:15.351472       1 pmd-lvm.go:326] Create fsdax-namespaces in region0, allowed 50 %, real align 1073741824:</span>
<span class="go">total       :      68719476736</span>
<span class="go">avail       :      68719476736</span>
<span class="go">can use     :      34359738368</span>
<span class="go">I0526 14:40:15.351968       1 pmd-lvm.go:341] Calculated canUse:34359738368, available by Region info:68719476736</span>
<span class="go">I0526 14:40:15.352034       1 pmd-lvm.go:358] Create 34359738368-bytes fsdax-namespace</span>
<span class="go">I0526 14:40:15.355296       1 region.go:244] setting namespace sector size: 0</span>
<span class="go">I0526 14:40:15.357631       1 region.go:254] setting pfn</span>
<span class="go">I0526 14:40:15.793975       1 region.go:265] enabling namespace</span>
<span class="go">I0526 14:40:15.794737       1 exec.go:32] Executing: /sbin/pvs --noheadings -o vg_name /dev/pmem0</span>
<span class="go">I0526 14:40:15.806291       1 exec.go:69] /sbin/pvs: stderr:   Failed to find physical volume &quot;/dev/pmem0&quot;.</span>
<span class="go">I0526 14:40:15.814110       1 exec.go:50] /sbin/pvs terminated, with 0 bytes of stdout, 47 of combined output and error exit status 5</span>
<span class="go">I0526 14:40:15.814277       1 exec.go:32] Executing: /sbin/vgdisplay ndbus0region0fsdax</span>
<span class="go">I0526 14:40:15.821343       1 exec.go:69] /sbin/vgdisplay: stderr:   Volume group &quot;ndbus0region0fsdax&quot; not found</span>
<span class="go">I0526 14:40:15.821477       1 exec.go:69] /sbin/vgdisplay: stderr:   Cannot process volume group ndbus0region0fsdax</span>
<span class="go">I0526 14:40:15.831688       1 exec.go:50] /sbin/vgdisplay terminated, with 0 bytes of stdout, 95 of combined output and error exit status 5</span>
<span class="go">I0526 14:40:15.831841       1 pmd-lvm.go:418] No volume group with name ndbus0region0fsdax, mark for creation</span>
<span class="go">I0526 14:40:15.831998       1 exec.go:32] Executing: /sbin/vgcreate --force ndbus0region0fsdax /dev/pmem0</span>
<span class="go">I0526 14:40:15.851768       1 exec.go:69] /sbin/vgcreate: stdout:   Physical volume &quot;/dev/pmem0&quot; successfully created.</span>
<span class="go">I0526 14:40:15.852864       1 exec.go:69] /sbin/vgcreate: stderr:   WARNING: This metadata update is NOT backed up.</span>
<span class="go">I0526 14:40:15.852905       1 exec.go:69] /sbin/vgcreate: stdout:   Volume group &quot;ndbus0region0fsdax&quot; successfully created</span>
<span class="go">I0526 14:40:15.861623       1 exec.go:50] /sbin/vgcreate terminated, with 110 bytes of stdout, 160 of combined output and error &lt;nil&gt;</span>
<span class="go">I0526 14:40:15.861746       1 exec.go:32] Executing: /sbin/vgs ndbus0region0fsdax</span>
<span class="go">I0526 14:40:15.870096       1 exec.go:69] /sbin/vgs: stdout:   VG                 #PV #LV #SN Attr   VSize   VFree  </span>
<span class="go">I0526 14:40:15.870237       1 exec.go:69] /sbin/vgs: stdout:   ndbus0region0fsdax   1   0   0 wz--n- &lt;31.00g &lt;31.00g</span>
<span class="go">I0526 14:40:15.880273       1 exec.go:50] /sbin/vgs terminated, with 112 bytes of stdout, 112 of combined output and error &lt;nil&gt;</span>
<span class="go">I0526 14:40:15.880373       1 exec.go:32] Executing: /sbin/lvs --noheadings --nosuffix -o lv_name,lv_path,lv_size --units B ndbus0region0fsdax</span>
<span class="go">I0526 14:40:15.899066       1 exec.go:50] /sbin/lvs terminated, with 0 bytes of stdout, 0 of combined output and error &lt;nil&gt;</span>
<span class="go">I0526 14:40:15.899553       1 mount_linux.go:163] Detected OS without systemd</span>
<span class="go">I0526 14:40:15.900187       1 exec.go:32] Executing: /sbin/vgs --noheadings --nosuffix -o vg_name,vg_size,vg_free --units B ndbus0region0fsdax</span>
<span class="go">I0526 14:40:15.900189       1 server.go:52] Listening for connections on address: /csi/csi.sock</span>
<span class="go">I0526 14:40:15.912667       1 exec.go:69] /sbin/vgs: stdout:   ndbus0region0fsdax 33281802240 33281802240</span>
<span class="go">I0526 14:40:15.925819       1 exec.go:50] /sbin/vgs terminated, with 45 bytes of stdout, 45 of combined output and error &lt;nil&gt;</span>
<span class="go">I0526 14:40:15.926627       1 exec.go:32] Executing: /sbin/vgs --noheadings --nosuffix -o vg_name,vg_size,vg_free --units B ndbus0region0fsdax</span>
<span class="go">I0526 14:40:15.941874       1 exec.go:69] /sbin/vgs: stdout:   ndbus0region0fsdax 33281802240 33281802240</span>
<span class="go">I0526 14:40:15.954167       1 exec.go:50] /sbin/vgs terminated, with 45 bytes of stdout, 45 of combined output and error &lt;nil&gt;</span>
<span class="go">I0526 14:40:15.954661       1 pmem-csi-driver.go:304] PMEM-CSI ready. Capacity: 31740Mi maximum volume size, 31740Mi available, 31740Mi managed, 64Gi total</span>
<span class="go">I0526 14:40:15.955139       1 pmem-csi-driver.go:336] Prometheus endpoint started at http://[::]:10010/metrics</span>
</pre></div>
</div>
<p>Depending on the log level, only the <code class="docutils literal notranslate"><span class="pre">PMEM-CSI</span> <span class="pre">ready</span></code> line might be printed.</p>
<p>In a production environment, the <a class="reference external" href="#metrics-support">metrics support</a>
could be used to monitor available PMEM per node.</p>
</section>
</section>
<section id="kata-containers-support">
<h3>Kata Containers support<a class="headerlink" href="#kata-containers-support" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="design.html#kata-containers-support">Kata Containers support</a> gets enabled via
the <code class="docutils literal notranslate"><span class="pre">kataContainers</span></code> storage class parameter. PMEM-CSI then
creates a filesystem inside a partition inside a file. When such a volume
is used inside Kata Containers, the Kata Containers runtime makes sure that
the filesystem is mounted on an emulated NVDIMM device with full DAX support.</p>
<p>On the host, PMEM-CSI will try to mount through a loop device with <code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">dax</span></code> but proceed without <code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">dax</span></code> when the kernel does not support
that. Currently Linux up to and including 5.4 do not support it and it
is unclear when that support will be added In other words, on the host
such volumes are usable, but only without DAX.</p>
<p>When disabled, volumes support DAX on the host and are usable without
DAX inside Kata Containers.</p>
<p><a class="reference external" href="#raw-block-volumes">Raw block volumes</a> are only supported with
<code class="docutils literal notranslate"><span class="pre">kataContainers:</span> <span class="pre">false</span></code>. Attempts to create them with <code class="docutils literal notranslate"><span class="pre">kataContainers:</span> <span class="pre">true</span></code> are rejected.</p>
<p>At the moment (= Kata Containers 1.11.0-rc0), only Kata Containers
with QEMU enable the special support for such volumes. Without QEMU or
with older releases of Kata Containers, the volume is still usable
through the normal remote filesystem support (9p or virtio-fs). Support
for Cloud Hypervisor is <a class="reference external" href="https://github.com/kata-containers/runtime/issues/2575">in
progress</a>.</p>
<p>With Kata Containers for QEMU, the VM must be configured appropriately
to allow adding the PMEM volumes to their address space. This can be
done globally by setting the <code class="docutils literal notranslate"><span class="pre">memory_offset</span></code> in the
<a class="reference external" href="https://github.com/kata-containers/runtime/blob/ee985a608015d81772901c1d9999190495fc9a0a/cli/config/configuration-qemu.toml.in#L86-L91"><code class="docutils literal notranslate"><span class="pre">configuration-qemu.toml</span></code>
file</a>
or per-pod by setting the
<a class="reference external" href="https://github.com/kata-containers/documentation/blob/master/how-to/how-to-set-sandbox-config-kata.md#hypervisor-options"><code class="docutils literal notranslate"><span class="pre">io.katacontainers.config.hypervisor.memory_offset</span></code>
label</a>
in the pod meta data. In both cases, the value has to be large enough
for all PMEM volumes used by the pod, otherwise pod creation will fail
with an error similar to this:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Error: container create failed: QMP command failed: not enough space, currently 0x8000000 in use of total space for memory devices 0x3c100000</span>
</pre></div>
</div>
<p>The examples for usage of Kata Containers <a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common/pmem-kata-app-ephemeral.yaml">with
ephemeral</a> and
<a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common/pmem-kata-app.yaml">persistent</a> volumes use the pod
label. They assume that the <code class="docutils literal notranslate"><span class="pre">kata-qemu</span></code> runtime class <a class="reference external" href="https://github.com/kata-containers/packaging/tree/1.11.0-rc0/kata-deploy#run-a-sample-workload">is
installed</a>.</p>
<p>For the QEMU test cluster,
<a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/test/setup-kata-containers.sh"><code class="docutils literal notranslate"><span class="pre">setup-kata-containers.sh</span></code></a> can be
used to install Kata Containers. However, this currently only works on
Clear Linux because on Fedora, the Docker container runtime is used
and Kata Containers does not support that one.</p>
</section>
<section id="ephemeral-inline-volumes">
<h3>Ephemeral inline volumes<a class="headerlink" href="#ephemeral-inline-volumes" title="Permalink to this headline">¶</a></h3>
<section id="kubernetes-csi-specific">
<h4>Kubernetes CSI specific<a class="headerlink" href="#kubernetes-csi-specific" title="Permalink to this headline">¶</a></h4>
<p>This is the original implementation of ephemeral inline volumes for
CSI drivers in Kubernetes. It is currently available as a beta feature
in Kubernetes.</p>
<p>Volume requests <a class="reference external" href="https://kubernetes-csi.github.io/docs/ephemeral-local-volumes.html">embedded in the pod spec with the <code class="docutils literal notranslate"><span class="pre">csi</span></code> field</a> are provisioned as
ephemeral volumes. The volume request could use below fields as
<a class="reference external" href="https://kubernetes.io/docs/concepts/storage/volumes/#csi"><code class="docutils literal notranslate"><span class="pre">volumeAttributes</span></code></a>:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>key</th>
<th>meaning</th>
<th>optional</th>
<th>values</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>size</code></td>
<td>Size of the requested ephemeral volume as <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-memory">Kubernetes memory string</a> ("1Mi" = 1024*1024 bytes, "1e3K = 1000000 bytes)</td>
<td>No</td>
<td></td>
</tr>
<tr>
<td><code>eraseAfter</code></td>
<td>Clear all data by overwriting with zeroes after use and before<br> deleting the volume</td>
<td>Yes</td>
<td><code>true</code> (default),<br> <code>false</code></td>
</tr>
<tr>
<td><code>kataContainers</code></td>
<td>Prepare volume for use in Kata Containers.</td>
<td>Yes</td>
<td><code>false/0/f/FALSE</code> (default),<br> <code>true/1/t/TRUE</code></td>
</tr>
</tbody>
</table><p>Try out ephemeral volume usage with the provided <a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common/pmem-app-ephemeral.yaml">example
application</a>.</p>
</section>
<section id="generic">
<h4>Generic<a class="headerlink" href="#generic" title="Permalink to this headline">¶</a></h4>
<p>This approach was introduced in <a class="reference external" href="https://kubernetes.io/blog/2020/09/01/ephemeral-volumes-with-storage-capacity-tracking/">Kubernetes
1.19</a>
with the goal of using them for PMEM-CSI instead of the older
approach. In contrast CSI ephemeral inline volumes, no changes are
needed in CSI drivers, so PMEM-CSI already fully supports this if the
cluster has the feature enabled. See
<a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common/pmem-app-generic-ephemeral.yaml"><code class="docutils literal notranslate"><span class="pre">pmem-app-generic-ephemeral.yaml</span></code></a>
for an example.</p>
<p>When using generic ephemeral inline volumes together with <a class="reference external" href="#storage-capacity-tracking">storage
capacity tracking</a>, the <a class="reference external" href="#enable-scheduler-extensions">PMEM-CSI
scheduler extensions</a> are not needed
anymore.</p>
</section>
</section>
<section id="raw-block-volumes">
<h3>Raw block volumes<a class="headerlink" href="#raw-block-volumes" title="Permalink to this headline">¶</a></h3>
<p>Applications can use volumes provisioned by PMEM-CSI as <a class="reference external" href="https://kubernetes.io/blog/2019/03/07/raw-block-volume-support-to-beta/">raw block
devices</a>. Such
volumes use the same “fsdax” namespace mode as filesystem volumes
and therefore are block devices. That mode only supports dax (=
<code class="docutils literal notranslate"><span class="pre">mmap(MAP_SYNC)</span></code>) through a filesystem. Pages mapped on the raw block
device go through the Linux page cache. Applications have to format
and mount the raw block volume themselves if they want dax. The
advantage then is that they have full control over that part.</p>
<p>For provisioning a PMEM volume as raw block device, one has to create a
<code class="docutils literal notranslate"><span class="pre">PersistentVolumeClaim</span></code> with <code class="docutils literal notranslate"><span class="pre">volumeMode:</span> <span class="pre">Block</span></code>. See example <a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common/pmem-pvc-block-volume.yaml">PVC</a> and
<a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/common/pmem-app-block-volume.yaml">application</a> for usage reference.</p>
<p>That example demonstrates how to handle some details:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mkfs.ext4</span></code> needs <code class="docutils literal notranslate"><span class="pre">-b</span> <span class="pre">4096</span></code> to produce volumes that support dax;
without it, the automatic block size detection may end up choosing
an unsuitable value depending on the volume size.</p></li>
<li><p><a class="reference external" href="https://github.com/kubernetes/kubernetes/issues/85624">Kubernetes bug #85624</a>
must be worked around to format and mount the raw block device.</p></li>
</ul>
</section>
<section id="enable-scheduler-extensions">
<h3>Enable scheduler extensions<a class="headerlink" href="#enable-scheduler-extensions" title="Permalink to this headline">¶</a></h3>
<p>The PMEM-CSI scheduler extender and admission webhook are provided by
the PMEM-CSI controller. They need to be enabled during deployment via
the <code class="docutils literal notranslate"><span class="pre">--schedulerListen=[&lt;listen</span> <span class="pre">address&gt;]:&lt;port&gt;</span></code> parameter. The
listen address is optional and can be left out. The port is where a
HTTPS server will run.</p>
<p>The controller needs TLS certificates which must be created in
advance. The YAML files expects them in a secret called
<code class="docutils literal notranslate"><span class="pre">pmem-csi-intel-com-controller-secret</span></code> and will not work without one.
The operator is more flexible and creates a driver without the
controller by default. This can be changed by setting the
<code class="docutils literal notranslate"><span class="pre">controllerTLSSecret</span></code> field in the <code class="docutils literal notranslate"><span class="pre">PmemCSIDeployment</span></code> API.</p>
<p>That secret must contain the following data items:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ca.crt</span></code>: root CA certificate</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tls.key</span></code>: secret key of the webhook</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tls.crt</span></code>: public key of the webhook</p></li>
</ul>
<p>The webhook certificate must include host names that match how the
webhooks are going to be called by the <code class="docutils literal notranslate"><span class="pre">kube-apiserver</span></code>
(i.e. <code class="docutils literal notranslate"><span class="pre">pmem-csi-intel-com-scheduler.pmem-csi.svc</span></code> for a
deployment with the <code class="docutils literal notranslate"><span class="pre">pmem-csi.intel.com</span></code> driver name in the <code class="docutils literal notranslate"><span class="pre">pmem-csi</span></code>
namespace) and by the <code class="docutils literal notranslate"><span class="pre">kube-scheduler</span></code> (might be the same service name, through some external
load balancer or <code class="docutils literal notranslate"><span class="pre">127.0.0.1</span></code> when using the node port workaround
described below).</p>
<p>To enable the PMEM-CSI scheduler extender, a configuration file and an
additional <code class="docutils literal notranslate"><span class="pre">--config</span></code> parameter for <code class="docutils literal notranslate"><span class="pre">kube-scheduler</span></code> must be added to
the cluster control plane, or, if there is already such a
configuration file, one new entry must be added to the <code class="docutils literal notranslate"><span class="pre">extenders</span></code>
array. A full example is presented below.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">kube-scheduler</span></code> must be able to connect to the PMEM-CSI
controller via the <code class="docutils literal notranslate"><span class="pre">urlPrefix</span></code> in its configuration. In some clusters
it is possible to use cluster DNS and thus a symbolic service name. If
that is the case, then deploy the <a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/kustomize/scheduler/scheduler-service.yaml">scheduler
service</a> as-is
and use <code class="docutils literal notranslate"><span class="pre">https://pmem-csi-scheduler.default.svc</span></code> as <code class="docutils literal notranslate"><span class="pre">urlPrefix</span></code>. If
the PMEM-CSI driver is deployed in a namespace, replace <code class="docutils literal notranslate"><span class="pre">default</span></code> with
the name of that namespace.</p>
<p>In a cluster created with kubeadm, <code class="docutils literal notranslate"><span class="pre">kube-scheduler</span></code> is unable to use
cluster DNS because the pod it runs in is configured with
<code class="docutils literal notranslate"><span class="pre">hostNetwork:</span> <span class="pre">true</span></code> and without <code class="docutils literal notranslate"><span class="pre">dnsPolicy</span></code>. Therefore the cluster DNS
servers are ignored. There also is no special dialer as in other
clusters. As a workaround, the PMEM-CSI service can be exposed via a
fixed node port like 32000 on all nodes. Then
<code class="docutils literal notranslate"><span class="pre">https://127.0.0.1:32000</span></code> needs to be used as <code class="docutils literal notranslate"><span class="pre">urlPrefix</span></code>. Here’s how
the service can be created with that node port:</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir my-scheduler

<span class="gp">$ </span>cat &gt;my-scheduler/kustomization.yaml &lt;&lt;EOF
<span class="go">bases:</span>
<span class="go">  - ../deploy/kustomize/scheduler</span>
<span class="go">patchesJson6902:</span>
<span class="go">  - target:</span>
<span class="go">      version: v1</span>
<span class="go">      kind: Service</span>
<span class="go">      name: pmem-csi-intel-com-scheduler</span>
<span class="go">      namespace: pmem-csi</span>
<span class="go">    path: node-port-patch.yaml</span>
<span class="go">EOF</span>

<span class="gp">$ </span>cat &gt;my-scheduler/node-port-patch.yaml &lt;&lt;EOF
<span class="go">- op: add</span>
<span class="go">  path: /spec/ports/0/nodePort</span>
<span class="go">  value: 32000</span>
<span class="go">- op: add</span>
<span class="go">  path: /spec/type</span>
<span class="go">  value: NodePort</span>
<span class="go">EOF</span>

<span class="gp">$ </span>kubectl create --kustomize my-scheduler
</pre></div>
</div>
<p>When the node port is not needed, the scheduler service can be
created directly with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">kubectl create --kustomize deploy/kustomize/scheduler</span>
</pre></div>
</div>
<p>How to (re)configure <code class="docutils literal notranslate"><span class="pre">kube-scheduler</span></code> depends on the cluster. With
kubeadm it is possible to set all necessary options in advance before
creating the master node with <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">init</span></code>. A running cluster can
be modified with <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">upgrade</span></code>.</p>
<p>One additional
complication with kubeadm is that <code class="docutils literal notranslate"><span class="pre">kube-scheduler</span></code> by default doesn’t
trust any root CA. The following kubeadm config file solves
this together with enabling the scheduler configuration by
bind-mounting the root certificate that was used to sign the certificate used
by the scheduler extender into the location where the Go
runtime will find it. It works for Kubernetes &lt;= 1.18:</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo mkdir -p /var/lib/scheduler/
<span class="gp">$ </span>sudo cp _work/pmem-ca/ca.pem /var/lib/scheduler/ca.crt

<span class="gp"># </span>https://github.com/kubernetes/kubernetes/blob/52d7614a8ca5b8aebc45333b6dc8fbf86a5e7ddf/staging/src/k8s.io/kube-scheduler/config/v1alpha1/types.go#L38-L107
<span class="gp">$ </span>sudo sh -c <span class="s1">&#39;cat &gt;/var/lib/scheduler/scheduler-policy.cfg&#39;</span> &lt;&lt;EOF
<span class="go">{</span>
<span class="go">  &quot;kind&quot; : &quot;Policy&quot;,</span>
<span class="go">  &quot;apiVersion&quot; : &quot;v1&quot;,</span>
<span class="go">  &quot;extenders&quot; :</span>
<span class="go">    [{</span>
<span class="go">      &quot;urlPrefix&quot;: &quot;https://&lt;service name or IP&gt;:&lt;port&gt;&quot;,</span>
<span class="go">      &quot;filterVerb&quot;: &quot;filter&quot;,</span>
<span class="go">      &quot;prioritizeVerb&quot;: &quot;prioritize&quot;,</span>
<span class="go">      &quot;nodeCacheCapable&quot;: true,</span>
<span class="go">      &quot;weight&quot;: 1,</span>
<span class="go">      &quot;managedResources&quot;:</span>
<span class="go">      [{</span>
<span class="go">        &quot;name&quot;: &quot;pmem-csi.intel.com/scheduler&quot;,</span>
<span class="go">        &quot;ignoredByScheduler&quot;: true</span>
<span class="go">      }]</span>
<span class="go">    }]</span>
<span class="go">}</span>
<span class="go">EOF</span>

<span class="gp"># </span>https://github.com/kubernetes/kubernetes/blob/52d7614a8ca5b8aebc45333b6dc8fbf86a5e7ddf/staging/src/k8s.io/kube-scheduler/config/v1alpha1/types.go#L38-L107
<span class="gp">$ </span>sudo sh -c <span class="s1">&#39;cat &gt;/var/lib/scheduler/scheduler-config.yaml&#39;</span> &lt;&lt;EOF
<span class="go">apiVersion: kubescheduler.config.k8s.io/v1alpha1</span>
<span class="go">kind: KubeSchedulerConfiguration</span>
<span class="go">schedulerName: default-scheduler</span>
<span class="go">algorithmSource:</span>
<span class="go">  policy:</span>
<span class="go">    file:</span>
<span class="go">      path: /var/lib/scheduler/scheduler-policy.cfg</span>
<span class="go">clientConnection:</span>
<span class="gp">  # </span>This is where kubeadm puts it.
<span class="go">  kubeconfig: /etc/kubernetes/scheduler.conf</span>
<span class="go">EOF</span>

<span class="gp">$ </span>cat &gt;kubeadm.config &lt;&lt;EOF
<span class="go">apiVersion: kubeadm.k8s.io/v1beta1</span>
<span class="go">kind: ClusterConfiguration</span>
<span class="go">scheduler:</span>
<span class="go">  extraVolumes:</span>
<span class="go">    - name: config</span>
<span class="go">      hostPath: /var/lib/scheduler</span>
<span class="go">      mountPath: /var/lib/scheduler</span>
<span class="go">      readOnly: true</span>
<span class="go">    - name: cluster-root-ca</span>
<span class="go">      hostPath: /var/lib/scheduler/ca.crt</span>
<span class="go">      mountPath: /etc/ssl/certs/ca.crt</span>
<span class="go">      readOnly: true</span>
<span class="go">  extraArgs:</span>
<span class="go">    config: /var/lib/scheduler/scheduler-config.yaml</span>
<span class="go">EOF</span>

<span class="gp">$ </span>kubeadm init --config<span class="o">=</span>kubeadm.config
</pre></div>
</div>
<p>In Kubernetes 1.19, the configuration API of the scheduler
changed. The corresponding command for Kubernetes &gt;= 1.19 are:</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>sudo mkdir -p /var/lib/scheduler/
<span class="gp">$ </span>sudo cp _work/pmem-ca/ca.pem /var/lib/scheduler/ca.crt

<span class="gp"># </span>https://github.com/kubernetes/kubernetes/blob/1afc53514032a44d091ae4a9f6e092171db9fe10/staging/src/k8s.io/kube-scheduler/config/v1beta1/types.go#L44-L96
<span class="gp">$ </span>sudo sh -c <span class="s1">&#39;cat &gt;/var/lib/scheduler/scheduler-config.yaml&#39;</span> &lt;&lt;EOF
<span class="go">apiVersion: kubescheduler.config.k8s.io/v1beta1</span>
<span class="go">kind: KubeSchedulerConfiguration</span>
<span class="go">clientConnection:</span>
<span class="gp">  # </span>This is where kubeadm puts it.
<span class="go">  kubeconfig: /etc/kubernetes/scheduler.conf</span>
<span class="go">extenders:</span>
<span class="go">- urlPrefix: https://127.0.0.1:&lt;service name or IP&gt;:&lt;port&gt;</span>
<span class="go">  filterVerb: filter</span>
<span class="go">  prioritizeVerb: prioritize</span>
<span class="go">  nodeCacheCapable: true</span>
<span class="go">  weight: 1</span>
<span class="go">  managedResources:</span>
<span class="go">  - name: pmem-csi.intel.com/scheduler</span>
<span class="go">    ignoredByScheduler: true</span>
<span class="go">EOF</span>

<span class="gp">$ </span>cat &gt;kubeadm.config &lt;&lt;EOF
<span class="go">apiVersion: kubeadm.k8s.io/v1beta1</span>
<span class="go">kind: ClusterConfiguration</span>
<span class="go">scheduler:</span>
<span class="go">  extraVolumes:</span>
<span class="go">    - name: config</span>
<span class="go">      hostPath: /var/lib/scheduler</span>
<span class="go">      mountPath: /var/lib/scheduler</span>
<span class="go">      readOnly: true</span>
<span class="go">    - name: cluster-root-ca</span>
<span class="go">      hostPath: /var/lib/scheduler/ca.crt</span>
<span class="go">      mountPath: /etc/ssl/certs/ca.crt</span>
<span class="go">      readOnly: true</span>
<span class="go">  extraArgs:</span>
<span class="go">    config: /var/lib/scheduler/scheduler-config.yaml</span>
<span class="go">EOF</span>

<span class="gp">$ </span>kubeadm init --config<span class="o">=</span>kubeadm.config
</pre></div>
</div>
<p>It is possible to stop here without enabling the pod admission webhook.
To enable also that, continue as follows.</p>
<p>First of all, it is recommended to exclude all system pods from
passing through the web hook. This ensures that they can still be
created even when PMEM-CSI is down:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl label ns kube-system pmem-csi.intel.com/webhook<span class="o">=</span>ignore
</pre></div>
</div>
<p>This special label is configured in <a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/kustomize/webhook/webhook.yaml">the provided web hook
definition</a>. On Kubernetes &gt;=
1.15, it can also be used to let individual pods bypass the webhook by
adding that label. The CA gets configured explicitly, which is
supported for webhooks.</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>mkdir my-webhook

<span class="gp">$ </span>cat &gt;my-webhook/kustomization.yaml &lt;&lt;EOF
<span class="go">bases:</span>
<span class="go">  - ../deploy/kustomize/webhook</span>
<span class="go">patchesJson6902:</span>
<span class="go">  - target:</span>
<span class="go">      group: admissionregistration.k8s.io</span>
<span class="go">      version: v1beta1</span>
<span class="go">      kind: MutatingWebhookConfiguration</span>
<span class="go">      name: pmem-csi-intel-com-hook</span>
<span class="go">    path: webhook-patch.yaml</span>
<span class="go">EOF</span>

<span class="gp">$ </span>cat &gt;my-webhook/webhook-patch.yaml &lt;&lt;EOF
<span class="go">- op: replace</span>
<span class="go">  path: /webhooks/0/clientConfig/caBundle</span>
<span class="go">  value: $(base64 -w 0 _work/pmem-ca/ca.pem)</span>
<span class="go">EOF</span>

<span class="gp">$ </span>kubectl create --kustomize my-webhook
</pre></div>
</div>
</section>
<section id="storage-capacity-tracking">
<h3>Storage capacity tracking<a class="headerlink" href="#storage-capacity-tracking" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://kubernetes.io/blog/2020/09/01/ephemeral-volumes-with-storage-capacity-tracking/">Kubernetes
1.19</a>
introduces support for publishing and using storage capacity
information for pod scheduling. PMEM-CSI must be deployed
differently to use this feature:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">external-provisioner</span></code> must be told to publish storage capacity
information via command line arguments.</p></li>
<li><p>A flag in the CSI driver information must be set for the Kubernetes
scheduler, otherwise it ignores that information when considering
pods with unbound volume.</p></li>
</ul>
<p>Because the <code class="docutils literal notranslate"><span class="pre">CSIStorageCapacity</span></code> feature is still alpha in 1.19 and
driver deployment would fail on a cluster without support for it, none
of the normal deployment files nor the operator enable that. Instead,
special kustomize variants are provided in
<code class="docutils literal notranslate"><span class="pre">deploy/kubernetes-1.19-alpha*</span></code>.</p>
<p>They can be used for example in the QEMU test cluster with:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span><span class="nv">TEST_KUBERNETES_VERSION</span><span class="o">=</span><span class="m">1</span>.19 make start
<span class="go">...</span>
<span class="gp">$ </span><span class="nv">TEST_KUBERNETES_FLAVOR</span><span class="o">=</span>-alpha test/setup-deployment.sh
<span class="go">INFO: deploying from /nvme/gopath/src/github.com/intel/pmem-csi/deploy/kubernetes-1.19-alpha/lvm/testing</span>?ref=ecb06af5d5ea2b16705571e94a95f7ef07976c5d
<span class="go">...</span>
</pre></div>
</div>
</section>
<section id="metrics-support">
<h3>Metrics support<a class="headerlink" href="#metrics-support" title="Permalink to this headline">¶</a></h3>
<p>Metrics support is controlled by command line options of the PMEM-CSI
driver binary and of the CSI sidecars. Annotations and named container
ports make it possible to discover these data scraping endpoints. The
<a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/kustomize/kubernetes-with-metrics/kustomization.yaml">metrics kustomize
base</a>
adds all of that to the pre-generated deployment files. The operator
also enables the metrics support.</p>
<p>Access to metrics data is not restricted (no TLS, no client
authorization) because the metrics data is not considered confidential
and access control would just make client configuration unnecessarily
complex.</p>
<section id="metrics-data">
<h4>Metrics data<a class="headerlink" href="#metrics-data" title="Permalink to this headline">¶</a></h4>
<p>PMEM-CSI exposes metrics data about the Go runtime, Prometheus, CSI
method calls, and PMEM-CSI:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>build_info</code></td>
<td>gauge</td>
<td>A metric with a constant '1' value labeled by version.</td>
</tr>
<tr>
<td><code>scheduler_request_duration_seconds</code></td>
<td>histogram</td>
<td>Latencies for PMEM-CSI scheduler HTTP requests by operation ("mutate", "filter", "status") and method ("post").</td>
</tr>
<tr>
<td><code>scheduler_in_flight_requests</code></td>
<td>gauge</td>
<td>Currently pending PMEM-CSI scheduler HTTP requests.</td>
</tr>
<tr>
<td><code>scheduler_requests_total</code></td>
<td>counter</td>
<td>Number of HTTP requests to the PMEM-CSI scheduler, regardless of operation and method.</td>
</tr>
<tr>
<td><code>scheduler_response_size_bytes</code></td>
<td>histogram</td>
<td>Histogram of response sizes for PMEM-CSI scheduler requests, regardless of operation and method.</td>
</tr>
<tr>
<td><code>csi_[sidecar\|plugin]_operations_seconds</code></td>
<td>histogram</td>
<td>gRPC call duration and error code, for sidecar to driver (aka plugin) communication.</td>
</tr>
<tr>
<td><code>go_*</code></td>
<td></td>
<td><a href="https://github.com/prometheus/client_golang/blob/master/prometheus/go_collector.go">Go runtime information</a></td>
</tr>
<tr>
<td><code>pmem_amount_available</code></td>
<td>gauge</td>
<td>Remaining amount of PMEM on the host that can be used for new volumes.</td>
</tr>
<tr>
<td><code>pmem_amount_managed</code></td>
<td>gauge</td>
<td>Amount of PMEM on the host that is managed by PMEM-CSI.</td>
</tr>
<tr>
<td><code>pmem_amount_max_volume_size</code></td>
<td>gauge</td>
<td>The size of the largest PMEM volume that can be created.</td>
</tr>
<tr>
<td><code>pmem_amount_total</code></td>
<td>gauge</td>
<td>Total amount of PMEM on the host.</td>
</tr>
<tr>
<td><code>process_*</code></td>
<td></td>
<td><a href="https://github.com/prometheus/client_golang/blob/master/prometheus/process_collector.go">Process information</a></td>
</tr>
<tr>
<td><code>promhttp_metric_handler_requests_in_flight</code></td>
<td>gauge</td>
<td>Current number of scrapes being served.</td>
</tr>
<tr>
<td><code>promhttp_metric_handler_requests_total</code></td>
<td>counter</td>
<td>Total number of scrapes by HTTP status code.</td>
</tr>
</tbody>
</table><p>This list is tentative and may still change as long as metrics support
is alpha. To see all available data, query a container. Different
containers provide different data. For example, the controller
provides:</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>kubectl port-forward pmem-csi-intel-com-controller-0 <span class="m">10010</span>
<span class="go">Forwarding from 127.0.0.1:10010 -&gt; 10010</span>
<span class="go">Forwarding from [::1]:10010 -&gt; 10010</span>
</pre></div>
</div>
<p>And in another shell:</p>
<div class="highlight-ShellSession notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>curl --silent http://localhost:10010/metrics <span class="p">|</span> grep <span class="s1">&#39;# &#39;</span>
<span class="gp"># </span>HELP build_info A metric with a constant <span class="s1">&#39;1&#39;</span> value labeled by version.
<span class="gp"># </span>TYPE build_info gauge
<span class="go">...</span>
</pre></div>
</div>
</section>
<section id="prometheus-example">
<h4>Prometheus example<a class="headerlink" href="#prometheus-example" title="Permalink to this headline">¶</a></h4>
<p>An <a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/prometheus.yaml">extension of the scrape config</a> is
necessary for <a class="reference external" href="https://prometheus.io/">Prometheus</a>. When deploying
<a class="reference external" href="https://hub.helm.sh/charts/stable/prometheus">Prometheus via Helm</a>,
that file can be added to the default configuration with the <code class="docutils literal notranslate"><span class="pre">-f</span></code>
parameter. The following example works for the <a class="reference external" href="autotest.html#qemu-and-kubernetes">QEMU-based
cluster</a> and Helm v3.1.2. In a real
production deployment, some kind of persistent storage should be
provided. The <a class="reference external" href="https://github.com/intel/pmem-csi/blob/ecb06af5d5ea2b16705571e94a95f7ef07976c5d/deploy/prometheus.yaml">URL</a> can be used instead of
the file name, too.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>helm install prometheus stable/prometheus <span class="se">\</span>
     --set alertmanager.persistentVolume.enabled<span class="o">=</span>false,server.persistentVolume.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
     -f deploy/prometheus.yaml
<span class="go">NAME: prometheus</span>
<span class="go">LAST DEPLOYED: Tue Aug 18 18:04:27 2020</span>
<span class="go">NAMESPACE: default</span>
<span class="go">STATUS: deployed</span>
<span class="go">REVISION: 1</span>
<span class="go">TEST SUITE: None</span>
<span class="go">NOTES:</span>
<span class="go">The Prometheus server can be accessed via port 80 on the following DNS name from within your cluster:</span>
<span class="go">prometheus-server.default.svc.cluster.local</span>


<span class="go">Get the Prometheus server URL by running these commands in the same shell:</span>
<span class="go">  export POD_NAME=$(kubectl get pods --namespace default -l &quot;app=prometheus,component=server&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;)</span>
<span class="go">  kubectl --namespace default port-forward $POD_NAME 9090</span>
<span class="gp">#</span><span class="c1">################################################################################</span>
<span class="gp">#</span><span class="c1">#####   WARNING: Persistence is disabled!!! You will lose your data when   #####</span>
<span class="gp">#</span><span class="c1">#####            the Server pod is terminated.                             #####</span>
<span class="gp">#</span><span class="c1">################################################################################</span>

<span class="go">...</span>
</pre></div>
</div>
<p>After running this <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">port-forward</span></code> command, it is possible to
access the <a class="reference external" href="https://prometheus.io/docs/prometheus/latest/getting_started/#using-the-expression-browser">Prometheus web
interface</a>
and run some queries there. Here are some examples for the QEMU test
cluster with two volumes created on node <code class="docutils literal notranslate"><span class="pre">pmem-csi-pmem-govm-worker2</span></code>.</p>
<p>Available PMEM as percentage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pmem_amount_available</span> <span class="o">/</span> <span class="n">pmem_amount_managed</span>
</pre></div>
</div>
<table border="1" class="docutils">
<thead>
<tr>
<th>Result variable</th>
<th>Value</th>
<th>Tags</th>
</tr>
</thead>
<tbody>
<tr>
<td>none</td>
<td>0.7332986065893997</td>
<td>instance = 10.42.0.1:10010</td>
</tr>
<tr>
<td></td>
<td></td>
<td>job = pmem-csi-containers</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_namespace = default</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_container_name = pmem-driver</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_name = pmem-csi-node-dfkrw</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_node_name = pmem-csi-pmem-govm-worker2</td>
</tr>
<tr>
<td></td>
<td></td>
<td>node = pmem-csi-pmem-govm-worker2</td>
</tr>
<tr>
<td></td>
<td>1</td>
<td>instance = 10.36.0.1:10010</td>
</tr>
<tr>
<td></td>
<td></td>
<td>job = pmem-csi-containers</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_namespace = default</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_container_name = pmem-driver</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_name = pmem-csi-node-z5vnp</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_node_name pmem-csi-pmem-govm-worker3</td>
</tr>
<tr>
<td></td>
<td></td>
<td>node = pmem-csi-pmem-govm-worker3</td>
</tr>
<tr>
<td></td>
<td>1</td>
<td>instance = 10.44.0.1:10010</td>
</tr>
<tr>
<td></td>
<td></td>
<td>job = pmem-csi-containers</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_namespace = default</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_container_name = pmem-driver</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_name = pmem-csi-node-zzmsd</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_node_name = pmem-csi-pmem-govm-worker1</td>
</tr>
<tr>
<td></td>
<td></td>
<td>node = pmem-csi-pmem-govm-worker1</td>
</tr>
</tbody>
</table><p>Number of <code class="docutils literal notranslate"><span class="pre">CreateVolume</span></code> calls in nodes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pmem_csi_node_operations_seconds_count</span><span class="p">{</span><span class="n">method_name</span><span class="o">=</span><span class="s2">&quot;/csi.v1.Controller/CreateVolume&quot;</span><span class="p">}</span>
</pre></div>
</div>
<table border="1" class="docutils">
<thead>
<tr>
<th>Result variable</th>
<th>Value</th>
<th>Tags</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>pmem_csi_node_operations_seconds_count</code></td>
<td>2</td>
<td>driver_name = pmem-csi.intel.com</td>
</tr>
<tr>
<td></td>
<td></td>
<td>grpc_status_code = OK</td>
</tr>
<tr>
<td></td>
<td></td>
<td>instance = 10.42.0.1:10010</td>
</tr>
<tr>
<td></td>
<td></td>
<td>job = pmem-csi-containers</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_namespace = default</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_container_name = pmem-driver</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_name = pmem-csi-node-dfkrw</td>
</tr>
<tr>
<td></td>
<td></td>
<td>kubernetes_pod_node_name = pmem-csi-pmem-govm-worker2</td>
</tr>
<tr>
<td></td>
<td></td>
<td>method_name = /csi.v1.Controller/CreateVolume</td>
</tr>
<tr>
<td></td>
<td></td>
<td>node = pmem-csi-pmem-govm-worker2</td>
</tr>
</tbody>
</table></section>
</section>
</section>
<section id="pmem-csi-deployment-crd">
<h2>PMEM-CSI Deployment CRD<a class="headerlink" href="#pmem-csi-deployment-crd" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">PmemCSIDeployment</span></code> is a cluster-scoped Kubernetes resource in the
<code class="docutils literal notranslate"><span class="pre">pmem-csi.intel.com</span></code> API group. It describes how a PMEM-CSI driver
instance is to be created.</p>
<p>The operator will create objects in the namespace in which the
operator itself runs if the object type is namespaced.</p>
<p>The name of the deployment object is also used as CSI driver
name. This ensures that the name is unique and immutable. However,
name clashes with other CSI drivers are still possible, so the name
should meet the <a class="reference external" href="https://github.com/container-storage-interface/spec/blob/master/spec.md#getplugininfo">CSI
requirements</a>:</p>
<ul class="simple">
<li><p>domain name notation format, including a unique top-level domain</p></li>
<li><p>63 characters or less, beginning and ending with an alphanumeric
character ([a-z0-9A-Z]) with dashes (-), dots (.), and
alphanumerics between.</p></li>
</ul>
<p>The name is also used as prefix for the names of all objects created
for the deployment and for the local <code class="docutils literal notranslate"><span class="pre">/var/lib/&lt;name&gt;</span></code> state directory
on each node.</p>
<p><strong>NOTE</strong>: Starting from release v0.9.0 reconciling of the <code class="docutils literal notranslate"><span class="pre">Deployment</span></code>
CRD in <code class="docutils literal notranslate"><span class="pre">pmem-csi.intel.com/v1alpha1</span></code> API group is not supported by the
PMEM-CSI operator anymore. Such resources in the cluster must be migrated
manually to new the <code class="docutils literal notranslate"><span class="pre">PmemCSIDeployment</span></code> API.</p>
<p>The current API for <code class="docutils literal notranslate"><span class="pre">PmemCSIDeployment</span></code> resources is:</p>
<section id="pmemcsideployment">
<h3>PmemCSIDeployment<a class="headerlink" href="#pmemcsideployment" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion</td>
<td>string</td>
<td><code>pmem-csi.intel.com/v1beta1</code></td>
</tr>
<tr>
<td>kind</td>
<td>string</td>
<td><code>PmemCSIDeployment</code></td>
</tr>
<tr>
<td>metadata</td>
<td><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata">ObjectMeta</a></td>
<td>Object metadata, name used for CSI driver and as prefix for sub-objects</td>
</tr>
<tr>
<td>spec</td>
<td><a href="#deployment-spec">DeploymentSpec</a></td>
<td>Specification of the desired behavior of the deployment</td>
</tr>
</tbody>
</table><section id="deploymentspec">
<h4>DeploymentSpec<a class="headerlink" href="#deploymentspec" title="Permalink to this headline">¶</a></h4>
<p>Below specification fields are valid in all API versions unless noted otherwise in the description.</p>
<p>The default values are used by the operator when no value is set for a
field explicitly. Those defaults can change over time and are not part
of the API specification.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Field</th>
<th>Type</th>
<th>Description</th>
<th>Default Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>image</td>
<td>string</td>
<td>PMEM-CSI docker image name used for the deployment</td>
<td>the same image as the operator<sup>1</sup></td>
</tr>
<tr>
<td>provisionerImage</td>
<td>string</td>
<td><a href="https://kubernetes-csi.github.io/docs/external-provisioner.html">CSI provisioner</a> docker image name</td>
<td>latest <a href="https://kubernetes-csi.github.io/docs/external-provisioner.html">external provisioner</a> stable release image<sup>2</sup></td>
</tr>
<tr>
<td>nodeRegistrarImage</td>
<td>string</td>
<td><a href="https://github.com/kubernetes-csi/node-driver-registrar">CSI node driver registrar</a> docker image name</td>
<td>latest <a href="https://kubernetes-csi.github.io/docs/node-driver-registrar.html">node driver registrar</a> stable release image<sup>2</sup></td>
</tr>
<tr>
<td>pullPolicy</td>
<td>string</td>
<td>Docker image pull policy. either one of <code>Always</code>, <code>Never</code>, <code>IfNotPresent</code></td>
<td><code>IfNotPresent</code></td>
</tr>
<tr>
<td>logLevel</td>
<td>integer</td>
<td>PMEM-CSI driver logging level</td>
<td>3</td>
</tr>
<tr>
<td>logFormat</td>
<td>text</td>
<td>log output format</td>
<td>"text" or "json" <sup>3</sup></td>
</tr>
<tr>
<td>deviceMode</td>
<td>string</td>
<td>Device management mode to use. Supports one of <code>lvm</code> or <code>direct</code></td>
<td><code>lvm</code></td>
</tr>
<tr>
<td>controllerTLSSecret</td>
<td>string</td>
<td>Name of an existing secret in the driver's namespace which contains ca.crt, tls.crt and tls.key data for the scheduler extender and pod mutation webhook. A controller is started if (and only if) this secret is specified.</td>
<td>empty</td>
</tr>
<tr>
<td>mutatePods</td>
<td>Always/Try/Never</td>
<td>Defines how a mutating pod webhook is configured if a controller is started. The field is ignored if the controller is not enabled. "Never" disables pod mutation. "Try" configured it so that pod creation is allowed to proceed even when the webhook fails. "Always" requires that the webhook gets invoked successfully before creating a pod.</td>
<td>Try</td>
</tr>
<tr>
<td>schedulerNodePort</td>
<td>If non-zero, the scheduler service is created as a NodeService with that fixed port number. Otherwise that service is created as a cluster service. The number must be from the range reserved by Kubernetes for node ports. This is useful if the kube-scheduler cannot reach the scheduler extender via a cluster service.</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>controllerResources</td>
<td><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#resourcerequirements-v1-core">ResourceRequirements</a></td>
<td>Describes the compute resource requirements for controller pod. <br/><sup>4</sup><em>Deprecated and only available in <code>v1alpha1</code>.</em></td>
<td></td>
</tr>
<tr>
<td>nodeResources</td>
<td><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#resourcerequirements-v1-core">ResourceRequirements</a></td>
<td>Describes the compute resource requirements for the pods running on node(s). <br/><em><sup>4</sup>Deprecated and only available in <code>v1alpha1</code>.</em></td>
<td></td>
</tr>
<tr>
<td>controllerDriverResources</td>
<td><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#resourcerequirements-v1-core">ResourceRequirements</a></td>
<td>Describes the compute resource requirements for controller driver container running on master node. Available since <code>v1beta1</code>.</td>
<td></td>
</tr>
<tr>
<td>nodeDriverResources</td>
<td><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#resourcerequirements-v1-core">ResourceRequirements</a></td>
<td>Describes the compute resource requirements for the driver container running on worker node(s). <br/><em>Available since <code>v1beta1</code>.</em></td>
<td></td>
</tr>
<tr>
<td>provisionerResources</td>
<td><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#resourcerequirements-v1-core">ResourceRequirements</a></td>
<td>Describes the compute resource requirements for the <a href="https://kubernetes-csi.github.io/docs/external-provisioner.html">external provisioner</a> sidecar container. <br><em>Available since <code>v1beta1</code>.</em></td>
<td></td>
</tr>
<tr>
<td>nodeRegistrarResources</td>
<td><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.12/#resourcerequirements-v1-core">ResourceRequirements</a></td>
<td>Describes the compute resource requirements for the <a href="https://kubernetes-csi.github.io/docs/node-driver-registrar.html">driver registrar</a> sidecar container running on worker node(s). <br/><em>Available since <code>v1beta1</code>.</em></td>
<td></td>
</tr>
<tr>
<td>registryCert</td>
<td>string</td>
<td>Encoded tls certificate signed by a certificate authority used for driver's controller registry server</td>
<td>generated by operator self-signed CA</td>
</tr>
<tr>
<td>nodeControllerCert</td>
<td>string</td>
<td>Encoded tls certificate signed by a certificate authority used for driver's node controllers</td>
<td>generated by operator self-signed CA</td>
</tr>
<tr>
<td>registryKey</td>
<td>string</td>
<td>Encoded RSA private key used for signing by <code>registryCert</code></td>
<td>generated by the operator</td>
</tr>
<tr>
<td>nodeControllerKey</td>
<td>string</td>
<td>Encoded RSA private key used for signing by <code>nodeControllerCert</code></td>
<td>generated by the operator</td>
</tr>
<tr>
<td>caCert</td>
<td>string</td>
<td>Certificate of the CA by which the <code>registryCert</code> and <code>controllerCert</code> are signed</td>
<td>self-signed certificate generated by the operator</td>
</tr>
<tr>
<td>nodeSelector</td>
<td>string map</td>
<td>Labels to use for selecting Nodes on which PMEM-CSI driver should run.</td>
<td><code>{ "storage": "pmem" }</code></td>
</tr>
<tr>
<td>pmemPercentage</td>
<td>integer</td>
<td>Percentage of PMEM space to be used by the driver on each node. This is only valid for a driver deployed in <code>lvm</code> mode. This field can be modified, but by that time the old value may have been used already. Reducing the percentage is not supported.</td>
<td>100</td>
</tr>
<tr>
<td>labels</td>
<td>string map</td>
<td>Additional labels for all objects created by the operator. Can be modified after the initial creation, but removed labels will not be removed from existing objects because the operator cannot know which labels it needs to remove and which it has to leave in place.</td>
<td></td>
</tr>
<tr>
<td>kubeletDir</td>
<td>string</td>
<td>Kubelet's root directory path</td>
<td>/var/lib/kubelet</td>
</tr>
</tbody>
</table><p><sup>1</sup> To use the same container image as default driver image
the operator pod must set with below environment variables with
appropriate values:</p>
<ul class="simple">
<li><p>POD_NAME: Name of the operator pod. Namespace of the pod could be figured out by the operator.</p></li>
<li><p>OPERATOR_NAME: Name of the operator container. If not set, defaults to “pmem-csi-operator”</p></li>
</ul>
<p><sup>2</sup> Image versions depend on the Kubernetes release. The
operator dynamically chooses suitable image versions. Users have to
take care of that themselves when overriding the values.</p>
<p><sup>3</sup> In PMEM-CSI 0.9.0, “json” output is only available for
the PMEM-CSI container. The sidecars are still producing plain text
messages. This may change in the future. Also, the migration from
formatted log messages (= printf style) to structured log messages
(message plus key/value pairs) is not complete.</p>
<p><sup>4</sup> Pod level resource requirements (<code class="docutils literal notranslate"><span class="pre">nodeResources</span></code> and <code class="docutils literal notranslate"><span class="pre">controllerResources</span></code>)
are deprecated in favor of per-container resource requirements (<code class="docutils literal notranslate"><span class="pre">nodeDriverResources</span></code>, <code class="docutils literal notranslate"><span class="pre">nodeRegistrarResources</span></code>,
<code class="docutils literal notranslate"><span class="pre">controllerDriverResources</span></code> and <code class="docutils literal notranslate"><span class="pre">provisionerResources</span></code>).</p>
<p><strong>WARNING</strong>: although all fields can be modified and changes will be
propagated to the deployed driver, not all changes are safe. In
particular, changing the <code class="docutils literal notranslate"><span class="pre">deviceMode</span></code> will not work when there are
active volumes.</p>
</section>
<section id="deploymentstatus">
<h4>DeploymentStatus<a class="headerlink" href="#deploymentstatus" title="Permalink to this headline">¶</a></h4>
<p>A PMEM-CSI Deployment’s <code class="docutils literal notranslate"><span class="pre">status</span></code> field is a <code class="docutils literal notranslate"><span class="pre">DeploymentStatus</span></code> object, which
carries the detailed state of the driver deployment. It is comprised of <a class="reference external" href="#deployment-conditions">deployment
conditions</a>, <a class="reference external" href="#driver-component-status">driver component status</a>,
and a <code class="docutils literal notranslate"><span class="pre">phase</span></code> field. The phase of a PMEM-CSI deployment is a high-level summary
of where the the PmemCSIDployment is in its lifecycle.</p>
<p>The possible <code class="docutils literal notranslate"><span class="pre">phase</span></code> values and their meaning are as below:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>empty string</td>
<td>A new deployment.</td>
</tr>
<tr>
<td>Running</td>
<td>The operator has determined that the driver is usable<sup>1</sup>.</td>
</tr>
<tr>
<td>Failed</td>
<td>For some reason, the <code>PmemCSIDeployment</code> failed and cannot be progressed. The failure reason is placed in the <code>DeploymentStatus.Reason</code> field.</td>
</tr>
</tbody>
</table><p><sup>1</sup> This check has not been implemented yet. Instead, the deployment goes straight to <code class="docutils literal notranslate"><span class="pre">Running</span></code> after creating sub-resources.</p>
</section>
<section id="deployment-conditions">
<h4>Deployment Conditions<a class="headerlink" href="#deployment-conditions" title="Permalink to this headline">¶</a></h4>
<p>PMEM-CSI <code class="docutils literal notranslate"><span class="pre">DeploymentStatus</span></code> has an array of <code class="docutils literal notranslate"><span class="pre">conditions</span></code> through which the
PMEM-CSI Deployment has or has not passed. Below are the possible condition
types and their meanings:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Condition type</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>CertsReady</td>
<td>Driver certificates/secrets are available.</td>
</tr>
<tr>
<td>CertsVerified</td>
<td>Verified that the provided certificates are valid.</td>
</tr>
<tr>
<td>DriverDeployed</td>
<td>All the componentes required for the PMEM-CSI deployment have been deployed.</td>
</tr>
</tbody>
</table></section>
<section id="driver-component-status">
<h4>Driver component status<a class="headerlink" href="#driver-component-status" title="Permalink to this headline">¶</a></h4>
<p>PMEM-CSI <code class="docutils literal notranslate"><span class="pre">DeploymentStatus</span></code> has an array of <code class="docutils literal notranslate"><span class="pre">components</span></code> of type <code class="docutils literal notranslate"><span class="pre">DriverStatus</span></code>
in which the operator records the brief driver components status. This is
useful to know if all the driver instances of a deployment are ready.
Below are the fields and their meanings of <code class="docutils literal notranslate"><span class="pre">DriverStatus</span></code>:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Field</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>component</td>
<td>Represents the driver component type; one of <code>Controller</code> or <code>Node</code>.</td>
</tr>
<tr>
<td>status</td>
<td>Represents the state of the component; one of <code>Ready</code> or <code>NotReady</code>. Component becomes <code>Ready</code> if all the instances of the driver component are running. Otherwise, <code>NotReady</code>.</td>
</tr>
<tr>
<td>reason</td>
<td>A brief message that explains why the component is in this state.</td>
</tr>
<tr>
<td>lastUpdateTime</td>
<td>Time at which the status updated.</td>
</tr>
</tbody>
</table></section>
<section id="deployment-events">
<h4>Deployment Events<a class="headerlink" href="#deployment-events" title="Permalink to this headline">¶</a></h4>
<p>The PMEM-CSI operator posts events on the progress of a <code class="docutils literal notranslate"><span class="pre">PmemCSIDeployment</span></code>. If the
deployment is in the <code class="docutils literal notranslate"><span class="pre">Failed</span></code> state, then one can look into the event(s) using
<code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">describe</span></code> on that deployment for the detailed failure reason.</p>
<blockquote>
<div><p><strong>Note on multiple deployments</strong></p>
<p>Though the operator allows running multiple PMEM-CSI driver deployments, one
has to take extreme care of such deployments by ensuring that not more than
one driver ends up running on the same node(s). Nodes on which a PMEM-CSI
driver could run can be configured by using <code class="docutils literal notranslate"><span class="pre">nodeSelector</span></code> property of
<a class="reference external" href="#pmem-csi-deployment-crd"><code class="docutils literal notranslate"><span class="pre">DeploymentSpec</span></code></a>.</p>
</div></blockquote>
</section>
</section>
</section>
<section id="filing-issues-and-contributing">
<h2>Filing issues and contributing<a class="headerlink" href="#filing-issues-and-contributing" title="Permalink to this headline">¶</a></h2>
<p>Report a bug by <a class="reference external" href="https://github.com/intel/pmem-csi/issues">filing a new issue</a>.</p>
<p>Before making your first contribution, be sure to read the <a class="reference internal" href="DEVELOPMENT.html"><span class="doc">development documentation</span></a>
for guidance on code quality and branches.</p>
<p>Contribute by <a class="reference external" href="https://github.com/intel/pmem-csi/pulls">opening a pull request</a>.</p>
<p>Learn <a class="reference external" href="https://help.github.com/articles/using-pull-requests/">about pull requests</a>.</p>
<p><strong>Reporting a Potential Security Vulnerability:</strong> If you have discovered potential security vulnerability in PMEM-CSI, please send an e-mail to secure&#64;intel.com. For issues related to Intel Products, please visit <a class="reference external" href="https://security-center.intel.com">Intel Security Center</a>.</p>
<p>It is important to include the following details:</p>
<ul class="simple">
<li><p>The projects and versions affected</p></li>
<li><p>Detailed description of the vulnerability</p></li>
<li><p>Information on known exploits</p></li>
</ul>
<p>Vulnerability information is extremely sensitive. Please encrypt all security vulnerability reports using our <a class="reference external" href="https://www.intel.com/content/www/us/en/security-center/pgp-public-key.html">PGP key</a>.</p>
<p>A member of the Intel Product Security Team will review your e-mail and contact you to collaborate on resolving the issue. For more information on how Intel works to resolve security issues, see: <a class="reference external" href="https://www.intel.com/content/www/us/en/security-center/vulnerability-handling-guidelines.html">vulnerability handling guidelines</a>.</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="DEVELOPMENT.html" class="btn btn-neutral float-right" title="Develop and Contribute" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="design.html" class="btn btn-neutral float-left" title="Design and architecture" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel Corporation.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>